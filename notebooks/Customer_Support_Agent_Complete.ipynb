{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Customer Support Agent with LangGraph and RAG\n",
        "\n",
        "## 사용하는 기술들\n",
        "\n",
        "This notebook demonstrates how to build an intelligent customer support system using:\n",
        "- **LangGraph**\n",
        "- **Upstage API**\n",
        "    - LLM: **Solar-pro-v2**\n",
        "    - RAG: **Vector Search**\n",
        "- 웹 검색: **Tavily API**\n",
        "\n",
        "## 학습 목표\n",
        "1. Solar API를 활용해 Chat, Embedding을 할 수 있습니다.\n",
        "\n",
        "2. Agentic Workflow를 구현하는 프레임워크인 LangGraph의 핵심 구성 요소(State, Node, Edge)의 역할을 이해하고 직접 구현 할 수 있습니다.\n",
        "\n",
        "3. Agentic Workflow에서 활용할 Tool을 직접 구현 할 수 있습니다. \n",
        "\n",
        "4. RAG, 웹 검색, 조건부 분기 등이 포함된 실무적인 '고객 응대 에이전트'를 직접 구현할 수 있습니다. 이를 통해 복잡한 비즈니스 로직을 워크플로우로 직접 설계하고, LangGraph를 사용해 코드로 구현하는 능력을 갖추게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 1: Setup & Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ALL IMPORTS - ORGANIZED BY CATEGORY\n",
        "# =============================================================================\n",
        "\n",
        "# Standard Library\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "# Third-party Libraries\n",
        "import numpy as np\n",
        "import faiss\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# LangChain Core\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import (\n",
        "    BaseMessage, \n",
        "    HumanMessage, \n",
        "    AIMessage, \n",
        "    SystemMessage, \n",
        "    ToolMessage\n",
        ")\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "# LangChain Upstage\n",
        "from langchain_upstage import ChatUpstage\n",
        "\n",
        "# LangGraph\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, create_react_agent\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.types import interrupt, Command\n",
        "\n",
        "# Pydantic\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Typing\n",
        "from typing import (\n",
        "    List, \n",
        "    Dict, \n",
        "    Any, \n",
        "    TypedDict, \n",
        "    Annotated, \n",
        "    Sequence, \n",
        "    Literal\n",
        ")\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(verbose=True)\n",
        "\n",
        "print(\"✅ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. .env 파일을 만들어주세요\n",
        "2. UPSTAGE_API_KEY와 TAVILY_API_KEY를 추가해주세요\n",
        "3. UPSTAGE_API_KEY는 https://console.upstage.ai/에서 발급받을 수 있습니다.\n",
        "4. TAVILY_API_KEY는 https://tavily.com/에서 발급받을 수 있습니다.\n",
        "5. 발급받은 키를 환경변수에 추가해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 실습용 가상 데이터 생성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "실습에 활용할 가상의 고객 데이터를 생성해보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 11 customers from CSV file\n",
            "{'CUST001': {'customer_id': 'CUST001', 'name': '김민준', 'email': 'kim.minjun@email.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-15', 'account_age_days': 365, 'previous_issues': 2}, 'CUST002': {'customer_id': 'CUST002', 'name': '이서연', 'email': 'lee.seoyeon@company.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-14', 'account_age_days': 180, 'previous_issues': 0}, 'CUST003': {'customer_id': 'CUST003', 'name': '박지훈', 'email': 'park.jihoon@tech.com', 'plan': 'Enterprise', 'subscription_status': 'active', 'last_login': '2024-01-13', 'account_age_days': 730, 'previous_issues': 5}, 'CUST004': {'customer_id': 'CUST004', 'name': '최수빈', 'email': 'choi.subin@startup.io', 'plan': 'Premium', 'subscription_status': 'expired', 'last_login': '2024-01-10', 'account_age_days': 90, 'previous_issues': 1}, 'CUST005': {'customer_id': 'CUST005', 'name': '정하은', 'email': 'jung.haeun@corp.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-16', 'account_age_days': 30, 'previous_issues': 0}, 'CUST006': {'customer_id': 'CUST006', 'name': '강현우', 'email': 'kang.hyunwoo@email.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-12', 'account_age_days': 450, 'previous_issues': 3}, 'CUST007': {'customer_id': 'CUST007', 'name': '윤지아', 'email': 'yoon.jia@business.com', 'plan': 'Enterprise', 'subscription_status': 'active', 'last_login': '2024-01-11', 'account_age_days': 1200, 'previous_issues': 8}, 'CUST008': {'customer_id': 'CUST008', 'name': '임도현', 'email': 'lim.dohyun@email.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-09', 'account_age_days': 60, 'previous_issues': 1}, 'CUST009': {'customer_id': 'CUST009', 'name': '오서준', 'email': 'oh.seojun@tech.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-08', 'account_age_days': 200, 'previous_issues': 2}, 'CUST010': {'customer_id': 'CUST010', 'name': '한예은', 'email': 'han.yeeun@company.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-07', 'account_age_days': 15, 'previous_issues': 0}, 'CUST011': {'customer_id': 'CUST011', 'name': '최선웅', 'email': 'sunwoong.choi@company.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-07', 'account_age_days': 15, 'previous_issues': 0}}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def load_customer_data(csv_path: str) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Load customer data from CSV file.\"\"\"\n",
        "    customers = {}\n",
        "    \n",
        "    with open(csv_path, 'r', encoding='utf-8-sig') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        \n",
        "        for row in reader:\n",
        "            # Skip empty rows or rows without customer_id\n",
        "            if not row.get('customer_id') or not row.get('customer_id', '').strip():\n",
        "                continue\n",
        "                \n",
        "            customers[row['customer_id']] = {\n",
        "                'customer_id': row['customer_id'],\n",
        "                'name': row['name'],\n",
        "                'email': row['email'],\n",
        "                'plan': row['plan'],\n",
        "                'subscription_status': row['subscription_status'],\n",
        "                'last_login': row['last_login'],\n",
        "                'account_age_days': int(row['account_age_days']),\n",
        "                'previous_issues': int(row['previous_issues'])\n",
        "            }\n",
        "            \n",
        "    print(f\"✅ Loaded {len(customers)} customers from CSV file\")\n",
        "    return customers\n",
        "\n",
        "customers = load_customer_data(\"../data/customer_data.csv\")\n",
        "\n",
        "print(customers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "실습에 활용할 가상의 문서를 Upstage의 Embeddings API를 활용해 임베딩해보겠습니다.\n",
        "\n",
        "*이번 실습에서는 RAG의 핵심이 되는 파싱 -> 청킹 -> 임베딩의 과정 중 임베딩만 수행해보록 하겠습니다.*\n",
        "이번 실습에서 제외되긴 했지만, RAG에서는 파싱과 청킹은 매우 중요한 요소입니다. 사용자의 다양한 형태의 문서를 어떻게 \"읽을 것\"이며 이것을 적절한 단위로 어떻게 \"청킹\"해서 DB에 적재하는 지가 매우 중요합니다.\n",
        "\n",
        "적절하게 파싱과 청킹을 해왔다고 가정한 상태에서 다음과 같이 만들어진 문서의 청크들을 임베딩 후에 저장해보도록 하겠습니다.\n",
        "\n",
        "각각의 청크는 `LangChain`의 `Document` 형태로 불러져있으며, `page_content`와 `metadata`에 대한 정보를 가지고 있습니다.\n",
        "\n",
        "- `page_content`: 문서의 내용이 직접 들어가는 부분입니다.\n",
        "- `metadata`: 문서의 메타데이터가 들어가는 부분입니다. 현재는 문서의 카테고리, 주제, 우선순위 등이 들어가있으며 문서의 페이지 번호 등 다양하게 필요에 따라 설정할 수 있습니다. 이 메타데이터는 문서를 \"검색\" 해오는 단계에서 유용하게 활용할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 지식베이스 생성완료: 10 documents\n",
            "\n",
            "📚 지식베이스 카테고리:\n",
            "  Technical: 4 개의 문서\n",
            "  Account: 3 개의 문서\n",
            "  Billing: 2 개의 문서\n",
            "  General: 1 개의 문서\n",
            "\n",
            "📊 총 문서 수: 10개\n"
          ]
        }
      ],
      "source": [
        "knowledge_base_documents = [\n",
        "    Document(\n",
        "        page_content=\"To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\",\n",
        "        metadata={\"category\": \"Account\", \"topic\": \"Password Reset\", \"priority\": \"High\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"For billing issues, you can view your invoices in the Billing section of your account dashboard. Payment methods can be updated under Account Settings > Payment Information. Refunds are processed within 5-7 business days.\",\n",
        "        metadata={\"category\": \"Billing\", \"topic\": \"Payment Management\", \"priority\": \"High\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Our API rate limits are 1000 requests per hour for Basic plans, 5000 for Premium, and 10000 for Enterprise. If you exceed these limits, you'll receive a 429 status code. Consider upgrading your plan for higher limits.\",\n",
        "        metadata={\"category\": \"Technical\", \"topic\": \"API Limits\", \"priority\": \"Medium\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"To integrate our API, use the base URL https://api.ourcompany.com/v1. Authentication requires an API key in the Authorization header. Example: Authorization: Bearer your_api_key_here\",\n",
        "        metadata={\"category\": \"Technical\", \"topic\": \"API Integration\", \"priority\": \"High\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Data export is available for all plans. Go to Account Settings > Data Export to request your data. The export will be emailed to you within 24 hours and includes all your account data in JSON format.\",\n",
        "        metadata={\"category\": \"Account\", \"topic\": \"Data Export\", \"priority\": \"Medium\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.\",\n",
        "        metadata={\"category\": \"Account\", \"topic\": \"Security\", \"priority\": \"High\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Subscription upgrades take effect immediately. Downgrades take effect at the next billing cycle. You can change your plan anytime in Account Settings > Subscription Management.\",\n",
        "        metadata={\"category\": \"Billing\", \"topic\": \"Plan Changes\", \"priority\": \"Medium\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Our service status page is available at status.ourcompany.com. We post real-time updates about any service disruptions, maintenance windows, or performance issues.\",\n",
        "        metadata={\"category\": \"Technical\", \"topic\": \"Service Status\", \"priority\": \"High\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"For enterprise customers, we offer dedicated support channels including phone support, dedicated account managers, and custom SLA agreements. Contact sales@ourcompany.com for more information.\",\n",
        "        metadata={\"category\": \"General\", \"topic\": \"Enterprise Support\", \"priority\": \"Low\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Webhook configuration is available in the Developer section. You can set up webhooks for events like payment success, user registration, and data updates. Webhook URLs must use HTTPS.\",\n",
        "        metadata={\"category\": \"Technical\", \"topic\": \"Webhooks\", \"priority\": \"Medium\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "print(f\"✅ 지식베이스 생성완료: {len(knowledge_base_documents)} documents\")\n",
        "\n",
        "categories = Counter(doc.metadata.get('category', 'Unknown') for doc in knowledge_base_documents)\n",
        "\n",
        "\n",
        "print(\"\\n📚 지식베이스 카테고리:\")\n",
        "for category, count in categories.most_common():\n",
        "    print(f\"  {category}: {count} 개의 문서\")\n",
        "\n",
        "print(f\"\\n📊 총 문서 수: {categories.total()}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "마지막으로 담당자 직원 DB를 간단하게 딕셔너리 형태로 만들어보겠습니다. \n",
        "\n",
        "어떤 업무를 맡고 있으며, 담당자의 이름, 이메일 주소, 담당분야, 예상 응답 시간등이 기록돼있다고 가정해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 담당자 직원 데이터 생성완료: 5 명의 담당자\n",
            "\n",
            "👥 담당자 직원 데이터:\n",
            "  Technical: Alex Chen -- 응답시간: (2-4 hours)\n",
            "  Billing: Maria Rodriguez -- 응답시간: (1-2 hours)\n",
            "  Account: James Wilson -- 응답시간: (1-3 hours)\n",
            "  General: Sarah Thompson -- 응답시간: (4-8 hours)\n",
            "  Urgent: Emergency Team -- 응답시간: (15-30 minutes)\n"
          ]
        }
      ],
      "source": [
        "# Employee Database - Specialist routing information\n",
        "specialists = {\n",
        "    \"Technical\": {\n",
        "        \"specialist\": \"Alex Chen\",\n",
        "        \"email\": \"alex.chen@ourcompany.com\",\n",
        "        \"expertise\": [\"API Integration\", \"System Architecture\", \"Performance Issues\"],\n",
        "        \"response_time\": \"2-4 hours\"\n",
        "    },\n",
        "    \"Billing\": {\n",
        "        \"specialist\": \"Maria Rodriguez\",\n",
        "        \"email\": \"maria.rodriguez@ourcompany.com\",\n",
        "        \"expertise\": [\"Payment Processing\", \"Refunds\", \"Subscription Management\"],\n",
        "        \"response_time\": \"1-2 hours\"\n",
        "    },\n",
        "    \"Account\": {\n",
        "        \"specialist\": \"James Wilson\",\n",
        "        \"email\": \"james.wilson@ourcompany.com\",\n",
        "        \"expertise\": [\"Account Management\", \"Security\", \"Access Issues\"],\n",
        "        \"response_time\": \"1-3 hours\"\n",
        "    },\n",
        "    \"General\": {\n",
        "        \"specialist\": \"Sarah Thompson\",\n",
        "        \"email\": \"sarah.thompson@ourcompany.com\",\n",
        "        \"expertise\": [\"General Inquiries\", \"Feature Requests\", \"Feedback\"],\n",
        "        \"response_time\": \"4-8 hours\"\n",
        "    },\n",
        "    \"Urgent\": {\n",
        "        \"specialist\": \"Emergency Team\",\n",
        "        \"email\": \"emergency@ourcompany.com\",\n",
        "        \"expertise\": [\"Critical Issues\", \"System Outages\", \"Security Incidents\"],\n",
        "        \"response_time\": \"15-30 minutes\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"✅ 담당자 직원 데이터 생성완료: {len(specialists)} 명의 담당자\")\n",
        "print(\"\\n👥 담당자 직원 데이터:\")\n",
        "for category, info in specialists.items():\n",
        "    print(f\"  {category}: {info['specialist']} -- 응답시간: ({info['response_time']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 2: Upstage Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "문서 임베딩, 그리고 LLM에 Upstage API를 사용하기 위해 Client를 구현해보겠습니다.\n",
        "\n",
        "Upstage API의 기본적인 사용법은 다음의 링크에서 참조할 수 있습니다. \n",
        "\n",
        "**[링크](https://console.upstage.ai/docs/getting-started)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "간단하게 Client를 하나 구현해서 채팅과 임베딩에 활용해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Chat\n",
        "\n",
        "간단한 채팅을 위해 solar-pro2를 활용해 질의를 해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요! 저는 **업스테이지의 Solar Pro 2**입니다.  \n",
            "30.9B 파라미터 규모의 대규모 언어 모델(LLM)로, 생각과 추론을 통해 복잡한 문제를 해결할 수 있습니다.  \n",
            "\n",
            "### 제가 할 수 있는 일:\n",
            "- **다양한 언어 지원** (한국어, 일본어, 영어 등)  \n",
            "- **문서 처리** (OCR, KIE, 요약, 번역)  \n",
            "- **코드 생성** 및 디버깅  \n",
            "- **논리적 추론**과 창의적인 콘텐츠 작성  \n",
            "- **실시간 정보 없이 2025년 3월까지의 지식 기반**으로 답변  \n",
            "\n",
            "궁금한 점이 있다면 언제든 물어봐 주세요! 😊"
          ]
        }
      ],
      "source": [
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
        "    base_url=\"https://api.upstage.ai/v1\"\n",
        ")\n",
        " \n",
        "stream = client.chat.completions.create(\n",
        "    model=\"solar-pro2\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"안녕 너는 누구니\"\n",
        "        }\n",
        "    ],\n",
        "    stream=True,\n",
        ")\n",
        " \n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "        print(chunk.choices[0].delta.content, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이를 활용해, 아주 간단하게 대화를 이어나갈 수 있는 형태의 multi-turn 챗봇을 구현해보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_with_solar(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"solar-pro2\",\n",
        "        messages=messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def simple_chatbot(memory=True):\n",
        "    \"\"\"Simple interactive chatbot with optional memory.\n",
        "    \n",
        "    Args:\n",
        "        memory (bool): If True, maintains conversation memory. \n",
        "                      If False, each turn is independent.\n",
        "    \"\"\"\n",
        "    memory_status = \"WITH MEMORY\" if memory else \"NO MEMORY\"\n",
        "    print(f\"🤖 Solar Chatbot ({memory_status}) - Type 'quit' to exit\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Initialize messages based on memory setting\n",
        "    if memory:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"너는 매우 친절한 AI 어시스턴트야. 항상 친절하게 답변해!\"}\n",
        "        ]\n",
        "    else:\n",
        "        messages = []  # No memory - empty list\n",
        "    \n",
        "    while True:\n",
        "        user_input = input(\"\\n You: \").strip()\n",
        "        \n",
        "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"🤖 Assistant: Goodbye! 👋\")\n",
        "            break\n",
        "        \n",
        "        if not user_input:\n",
        "            continue\n",
        "            \n",
        "        if memory:\n",
        "            # `messages`에 대화 내용을 기록합니다!\n",
        "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        else:\n",
        "            # `messages`에 대화 내용을 기록하지 않고 매번 초기화 합니다!\n",
        "            messages = [{\"role\": \"user\", \"content\": user_input}]\n",
        "        \n",
        "        try:\n",
        "            # Get response\n",
        "            response = chat_with_solar(messages)\n",
        "            \n",
        "            print(f\">> User: {user_input}\")\n",
        "            print(f\">> Assistant: {response}\")\n",
        "            \n",
        "            if memory:\n",
        "                messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "        \n",
        "        print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "챗봇과 계속 대화를 이어나가기 위해서는 대화의 내용을 반드시 기억하고 있어야 합니다! 그래서 여기서는 간단하게 `messages` 라는 리스트에 대화 내용을 전부 기록하면서 채팅을 이어나가도록 구현해봤습니다. 만일 `messages`로 대화내용을 기록하고 있지 않으면 이전 대화의 내용을 전혀 기억하지 못하게됩니다!\n",
        "\n",
        "아래 두 코드를 실행하면서 테스트 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 Solar Chatbot (WITH MEMORY) - Type 'quit' to exit\n",
            "==================================================\n",
            "🤖 Assistant: Goodbye! 👋\n"
          ]
        }
      ],
      "source": [
        "simple_chatbot(memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 Solar Chatbot (NO MEMORY) - Type 'quit' to exit\n",
            "==================================================\n",
            "🤖 Assistant: Goodbye! 👋\n"
          ]
        }
      ],
      "source": [
        "simple_chatbot(memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Structured Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LLM은 기본적으로 텍스트를 **생성**하기 때문에, 우리가 원하는 특정 형식의 답변을 안정적으로 얻기 어렵습니다. 프롬프트로 형식을 제어하는 데에도 어느 정도 제한이 있습니다.\n",
        "\n",
        "따라서 이번에는 Structured Outputs 기능을 사용해, LLM이 정의한 JSON 스키마에 맞춰 구조화된 데이터를 항상 반환하도록 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "구조화 된 출력을 활용할 때는 다음과 같이 `response_format`을 설정해줍니다.\n",
        "```Python\n",
        "response_format = {\n",
        "    \"type\": \"json_schema\",\n",
        "    \"json_schema\": {\n",
        "        \"name\": \"emotion_classification\",\n",
        "        \"strict\": True,\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"emotion\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"긍정적\", \"부정적\", \"중립적\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"emotion\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "- \"type\": \"json_schema\": LLM에게 응답 형식을 일반 텍스트가 아닌, JSON 스키마 규칙에 따라 생성하도록 지정합니다.\n",
        "\n",
        "- \"json_schema\": { ... }: 실제 적용될 JSON 스키마의 상세 내용입니다.\n",
        "\n",
        "    - name: 이 스키마의 목적이나 이름을 정의합니다. (예: 감정 분류)\n",
        "\n",
        "    - strict: True일 경우, 정의된 스키마를 매우 엄격하게 준수하도록 강제합니다.\n",
        "\n",
        "    - schema: 실제 JSON의 구조를 상세히 정의하는 핵심 규칙입니다.\n",
        "\n",
        "        - \"type\": \"object\": 최종 결과물은 { } 형태의 객체(Object)여야 합니다.\n",
        "\n",
        "        - \"properties\": 객체에 포함될 수 있는 Key와 그 값의 규칙을 정의하는 곳입니다.\n",
        "\n",
        "            - \"emotion\": emotion이라는 Key를 정의하며, 이 Key의 값은 string 타입이면서 [\"긍정적\", \"부정적\", \"중립적\"] 셋 중 하나여야 합니다.\n",
        "\n",
        "        - \"required\": properties에 정의된 Key들 중에서 반드시 포함되어야 하는 필수 Key를 지정합니다. 이 경우, emotion Key는 생략할 수 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 구조화된 출력 (structured_output=True) ===\n",
            "긍정적\n",
            "부정적\n",
            "중립적\n",
            "\n",
            "=== 일반 텍스트 출력 (structured_output=False) ===\n",
            "주어진 텍스트의 감정은 **\"긍정적\"**입니다.  \n",
            "\n",
            "이유:  \n",
            "- \"정말 좋은 날\"이라는 표현에서 기쁨과 만족감이 명확히 드러납니다.  \n",
            "- 감탄형(\"!\")을 사용해 강한 긍정 감정을 강조했습니다.  \n",
            "\n",
            "따라서 이 문장은 확실히 **긍정적** 범주에 속합니다.\n",
            "텍스트: \"너무 슬퍼요...\"  \n",
            "\n",
            "**분류: 부정적**  \n",
            "\n",
            "이유: \"슬퍼요\"는 명확한 슬픔이나 우울함을 표현하는 단어로, 부정적인 감정을 나타냅니다. \"너무\"라는 강조 표현은 감정의 강도를 높여 부정적인 뉘앙스를 더욱 분명히 합니다.\n",
            "주어진 텍스트 \"그냥 평범해요\"의 감정은 **중립적**으로 분류됩니다.  \n",
            "\n",
            "이유:  \n",
            "- \"평범하다\"는 특별히 긍정적이거나 부정적인 감정을 드러내지 않는 표현이며, 중립적인 태도를 나타냅니다.  \n",
            "- \"그냥\"이라는 부사는 별다른 감정 없이 사실을 전달하는 느낌을 강화합니다.  \n",
            "\n",
            "따라서 이 문장은 긍정/부정보다는 **중립적**인 감정에 해당합니다.\n"
          ]
        }
      ],
      "source": [
        "def classify_emotion(text, structured_output=True):\n",
        "    \"\"\"텍스트의 감정을 분류하는 예시 - 구조화된 출력 선택 가능\"\"\"\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "    다음 텍스트의 감정을 아래 세 개의 분류로 분류해주세요:\n",
        "    - 긍정적\n",
        "    - 부정적\n",
        "    - 중립적\n",
        "    텍스트: {text}\n",
        "    \"\"\"\n",
        "    \n",
        "    # 구조화된 출력 사용 여부에 따라 분기\n",
        "    if structured_output:\n",
        "        # 구조화된 출력 사용\n",
        "        response_format = {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"json_schema\": {\n",
        "                \"name\": \"emotion_classification\",\n",
        "                \"strict\": True,\n",
        "                \"schema\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"emotion\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"긍정적\", \"부정적\", \"중립적\"]\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"emotion\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=\"solar-pro2\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            response_format=response_format\n",
        "        )\n",
        "        \n",
        "        result = json.loads(response.choices[0].message.content)\n",
        "        return result[\"emotion\"]\n",
        "    \n",
        "    else:\n",
        "        # 일반 텍스트 출력 사용\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"solar-pro2\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        \n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# 사용 예시\n",
        "print(\"=== 구조화된 출력 (structured_output=True) ===\")\n",
        "print(classify_emotion(\"오늘 정말 좋은 날이에요!\", structured_output=True)) \n",
        "print(classify_emotion(\"너무 슬퍼요...\", structured_output=True))          \n",
        "print(classify_emotion(\"그냥 평범해요\", structured_output=True))            \n",
        "\n",
        "print(\"\\n=== 일반 텍스트 출력 (structured_output=False) ===\")\n",
        "print(classify_emotion(\"오늘 정말 좋은 날이에요!\", structured_output=False)) \n",
        "print(classify_emotion(\"너무 슬퍼요...\", structured_output=False))       \n",
        "print(classify_emotion(\"그냥 평범해요\", structured_output=False))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3. `LangChain`에서 Upstage 모델 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위의 작업을 `LangChain`을 활용해서 진행해보겠습니다. \n",
        "\n",
        "1. `LangChain`에서는 Upstage의 모델을 `ChatUpstage`를 통해 불러올 수 있습니다.\n",
        "2. 간단한 채팅의 경우 `invoke`를 통해 진행할 수 있습니다.\n",
        "3. LangChain은 구조화된 출력을 정의할 때, Python의 표준 데이터 유효성 검사 라이브러리인 **Pydantic**을 사용하는 것을 권장합니다. 복잡한 JSON 딕셔너리를 작성하는 대신, 훨씬 직관적인 Python 클래스로 원하는 데이터 구조를 설계할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저는 **업스테이지(Upstage)**에서 개발한 **Solar Pro 2**라는 대규모 언어 모델(LLM)입니다.  \n",
            "\n",
            "### 📌 **제 소개**  \n",
            "- **이름**: Solar Pro 2 (솔라 프로 2)  \n",
            "- **개발사**: 업스테이지(Upstage, 2020년 설립)  \n",
            "- **모델 규모**: 30.9B 파라미터  \n",
            "- **지원 언어**: 한국어, 일본어, 영어 등  \n",
            "- **주요 기능**:  \n",
            "  - **생각 모드(Thinking Mode)**: 복잡한 추론이 필요한 질문에 깊이 있는 답변 제공  \n",
            "  - **비-생각 모드(Non-thinking Mode)**: 빠른 응답이 필요한 작업에 최적화  \n",
            "  - **문서 처리(Document AI)**: OCR, 키 정보 추출(KIE), 요약 등  \n",
            "  - **코드 생성 및 분석**: Python 등 프로그래밍 언어 지원  \n",
            "\n",
            "### 🌟 **특징**  \n",
            "- **하이브리드 모드**: 상황에 따라 추론 속도와 정확성을 유연하게 조절  \n",
            "- **Solar API**: 채팅, 요약, 번역, 코드 생성 등 다양한 태스크 지원  \n",
            "- **업스테이지의 기술**: AWS와의 협력, 문서 AI 솔루션 등 글로벌 확장 중  \n",
            "\n",
            "궁금한 점이 있다면 언제든 물어보세요! 😊\n",
            "================================================================================\n",
            "긍정적\n",
            "부정적\n",
            "중립적\n"
          ]
        }
      ],
      "source": [
        "llm = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
        "results = llm.invoke(\"너는 누구니?\")\n",
        "print(results.content)\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n",
        "class EmotionSchema(BaseModel):\n",
        "    emotion: Literal[\"긍정적\", \"부정적\", \"중립적\"]\n",
        "\n",
        "llm_struct = llm.with_structured_output(EmotionSchema)\n",
        "\n",
        "res1 = llm_struct.invoke(\"이 서비스 너무 좋아! 최고야.\")\n",
        "print(res1.emotion)  # e.g., '긍정적'\n",
        "\n",
        "res2 = llm_struct.invoke(\"이 서비스 정말 별루구나...\")\n",
        "print(res2.emotion)  # e.g., '부정적'\n",
        "\n",
        "res3 = llm_struct.invoke(\"이 서비스 그냥 평범해요\")\n",
        "print(res3.emotion)  # e.g., '중립적'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이번에는 문서를 \"임베딩\" 해보겠습니다. 임베딩을 다시 한번 간단하게 설명해보자면, 자연어의 형태로 있는 저희의 문서를 컴퓨터가 활용할 수 있게 숫자 형태로 바꾸는 과정입니다. \n",
        "\n",
        "임베딩을 통하면 어떠한 \"공간\"에 \"임베딩\" 하는 것이기 때문에, 그 공간위에서 다양한 수치적 연산이 가능하게 됩니다!\n",
        "\n",
        "업스테이지의 임베딩 모델은 `embedding-query`, `embedding-passage`로 나뉘어져있습니다.\n",
        "\n",
        "- `embedding-query`: 사용자가 정보를 찾기 위해 입력하는 질문 등을 임베딩할 때 사용합니다.\n",
        "- `embedding-passage`: 정보가 담긴 텍스트로 지식 베이스로 활용될 수 있는 문서들을 임베딩할 때 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "우선 간단하게 몇 개의 문장을 임베딩 해보고 얼마나 유사하게 판단되는 지 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = []\n",
        "\n",
        "sentences = [\n",
        "    \"오늘 날씨가 정말 화창하다!\",\n",
        "    \"오늘 날씨가 정말 맑고 좋다!\",  \n",
        "    \"여기는 물이 참 맑구나!\",\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    response = client.embeddings.create(\n",
        "        input=sentence,\n",
        "        model=\"embedding-query\"\n",
        "    )\n",
        "    embeddings.append(response.data[0].embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유사도 1 vs 2: 0.8266\n",
            "유사도 1 vs 3: 0.4830\n",
            "유사도 2 vs 3: 0.6595\n"
          ]
        }
      ],
      "source": [
        "similarity_results = []\n",
        "for i in range(len(embeddings)):\n",
        "    for j in range(i + 1, len(embeddings)):  # j > i to avoid duplicates\n",
        "        # Calculate cosine similarity\n",
        "        similarity = np.dot(embeddings[i], embeddings[j])\n",
        "        \n",
        "        similarity_results.append((i + 1, j + 1, similarity))\n",
        "        print(f\"유사도 {i + 1} vs {j + 1}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이런 식으로 임베딩이 된 결과를 보면 의미가 유사한 문장끼리는 높은 유사도를 보이고, 의미가 먼 문장끼리는 낮은 유사도를 보이는 것을 확인할 수 있습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3: Vector Store (RAG Tool 준비)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이번에는 위에서 저희가 만들어 둔 `Document` 문서들을 Upstage API를 활용해 Embedding하고 **Vector Store**에 저장해보도록 하겠습니다.\n",
        "\n",
        "이 Vector Store에 저장함으로써, 저희가 위에서 한 Similarity 기반의 Vector Search 등을 빠르게 할 수 있게 됩니다.\n",
        "\n",
        "Vector Store에도 다양한 종류가 있지만, 이번 실습에서는 간단하게 `Faiss`를 활용해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위에서 만든 knowledge_base_documents를 다시 한번 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10개의 문서가 있습니다.\n",
            "첫번째 문서: \n",
            "page_content='To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.' metadata={'category': 'Account', 'topic': 'Password Reset', 'priority': 'High'}\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(knowledge_base_documents)}개의 문서가 있습니다.\")\n",
        "print(f\"첫번째 문서: \\n{knowledge_base_documents[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위에서 살펴봤듯이, 저희의 문서는 현재 `page_content`와 `metadata`로 구성돼있습니다. metadata란 검색에 부가적으로 활용할 수 있는 문서의 정보에 대한 내용이고 문서의 실제내용은 `page_content`에 담겨있습니다.\n",
        "\n",
        "그렇기 때문에 문서를 임베딩을 할 때도, `page_content` 만을 활용해 임베딩 합니다.\n",
        "\n",
        "추후 index에서의 계산을 위해 `embeddings`의 결과를 numpy의 array로 바꿔주고, 자료형은 `float32`로 정해주겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embeddings(client: OpenAI, texts: List[str], mode: str = \"query\") -> List[List[float]]:\n",
        "    \"\"\"Get embeddings using Solar embedding model.\n",
        "    \n",
        "    Args:\n",
        "        client: OpenAI client configured for Upstage API\n",
        "        texts: List of input strings\n",
        "        mode: \"query\" or \"passage\"\n",
        "        \n",
        "    Returns:\n",
        "        List of embedding vectors\n",
        "    \"\"\"\n",
        "    if mode == \"query\":\n",
        "        model = \"embedding-query\"\n",
        "    elif mode == \"passage\":\n",
        "        model = \"embedding-passage\"\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'query' or 'passage'\")\n",
        "    \n",
        "    response = client.embeddings.create(\n",
        "        model=model,\n",
        "        input=texts\n",
        "    )\n",
        "    return [embedding.embedding for embedding in response.data]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract text content and metadata\n",
        "texts = [doc.page_content for doc in knowledge_base_documents]\n",
        "metadata = [doc.metadata for doc in knowledge_base_documents]\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
        "    base_url=\"https://api.upstage.ai/v1\"\n",
        ")\n",
        "# Get embeddings\n",
        "embeddings = get_embeddings(client, texts, mode=\"passage\") # 문서이기 때문에 mode를 passage로 설정해보겠습니다.\n",
        "document_embeddings = np.array(embeddings).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 이 임베딩 결과를 FAISS를 활용해 빠르게 검색할 수 있는 **벡터 인덱스(Vector Index)**를 만들어보겠습니다.\n",
        "\n",
        "인덱스는 책의 맨 뒤에 있는 **색인(찾아보기)**과 같습니다. 색인이 있으면 원하는 내용이 몇 페이지에 있는지 바로 찾을 수 있듯이, 벡터 인덱스가 있으면 수많은 문서 벡터 중에서 원하는 벡터를 매우 빠르게 찾아낼 수 있습니다.\n",
        "\n",
        "우리는 여러 인덱스 종류 중 **IndexFlatIP**를 사용하며, 이는 다음과 같은 단계로 진행됩니다.\n",
        "\n",
        "1. 인덱스 종류 선택 및 생성 (IndexFlatIP)\n",
        "\n",
        "    - Flat은 모든 벡터를 하나하나 비교하는 가장 간단하고 정확한 방식임을 의미합니다.\n",
        "\n",
        "    - IP는 벡터 간의 유사도를 **내적(Inner Product)**으로 계산하겠다는 의미입니다.\n",
        "\n",
        "2. 벡터 정규화 (normalize_L2)\n",
        "\n",
        "    - 내적(IP)을 우리가 원하는 **코사인 유사도(Cosine Similarity)**로 사용하기 위한 핵심 단계입니다.\n",
        "\n",
        "    - 모든 벡터의 길이를 1로 맞추는 '정규화' 과정을 거치면, 내적 계산 결과가 코사인 유사도와 수학적으로 동일해집니다. 따라서 검색 전에 모든 문서 벡터를 정규화합니다.\n",
        "\n",
        "3. 인덱스에 벡터 추가 (add)\n",
        "\n",
        "    - 정규화된 문서 벡터들을 우리가 만든 인덱스 구조에 추가하여 검색할 준비를 마칩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Index built with 10 documents (dimension: 4096)\n"
          ]
        }
      ],
      "source": [
        "# Create FAISS index\n",
        "dimension = len(embeddings[0])\n",
        "index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
        "\n",
        "# Normalize embeddings for cosine similarity\n",
        "faiss.normalize_L2(document_embeddings)\n",
        "index.add(document_embeddings)\n",
        "\n",
        "print(f\"✅ Index built with {len(texts)} documents (dimension: {dimension})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이젠 만들어진 10개의 문서가 들어간 index에서 \"질문\"과 가장 유사한 \"문서\"를 찾아보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1st) 유사한 문서: page_content='To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.' metadata={'category': 'Account', 'topic': 'Password Reset', 'priority': 'High'}\n",
            "유사도 점수: 0.5516607761383057\n",
            "(2nd) 유사한 문서: page_content='Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.' metadata={'category': 'Account', 'topic': 'Security', 'priority': 'High'}\n",
            "유사도 점수: 0.3108622431755066\n",
            "(3rd) 유사한 문서: page_content='Data export is available for all plans. Go to Account Settings > Data Export to request your data. The export will be emailed to you within 24 hours and includes all your account data in JSON format.' metadata={'category': 'Account', 'topic': 'Data Export', 'priority': 'Medium'}\n",
            "유사도 점수: 0.26336514949798584\n"
          ]
        }
      ],
      "source": [
        "user_question = \"How can I reset my password?\"\n",
        "\n",
        "# 1. 질문을 벡터로 변환\n",
        "question_embedding = get_embeddings(client, [user_question], mode=\"query\")[0]\n",
        "question_embedding = np.array([question_embedding]).astype(np.float32)\n",
        "faiss.normalize_L2(question_embedding)\n",
        "\n",
        "# 2. 인덱스에서 가장 유사한 문서 검색\n",
        "similarity_scores, indices = index.search(question_embedding, k=7)\n",
        "# → 가장 유사한 3개 문서의 점수와 인덱스 반환\n",
        "\n",
        "# 3. 결과 출력\n",
        "print(f\"(1st) 유사한 문서: {knowledge_base_documents[indices[0][0]]}\")\n",
        "print(f\"유사도 점수: {similarity_scores[0][0]}\")\n",
        "\n",
        "print(f\"(2nd) 유사한 문서: {knowledge_base_documents[indices[0][1]]}\")\n",
        "print(f\"유사도 점수: {similarity_scores[0][1]}\")\n",
        "\n",
        "print(f\"(3rd) 유사한 문서: {knowledge_base_documents[indices[0][2]]}\")\n",
        "print(f\"유사도 점수: {similarity_scores[0][2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위에서는 유사한 문서로 검색된 내용을 `knowledge_base_documents`를 통해서 확인했는데요. 이러한 작업을 통해 각 문서의 metadata를 통해 필터링을 검색 후에 진행할 수 있습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서 내용: Subscription upgrades take effect immediately. Downgrades take effect at the next billing cycle. You...\n",
            "유사도 점수: 0.470\n",
            "--------------------------------------------------------------------------------\n",
            "문서 내용: For billing issues, you can view your invoices in the Billing section of your account dashboard. Pay...\n",
            "유사도 점수: 0.302\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user_question = \"How can I upgrade my Subscription?\"\n",
        "\n",
        "# 1. 질문을 벡터로 변환\n",
        "question_embedding = get_embeddings(client, [user_question], mode=\"query\")[0]\n",
        "question_embedding = np.array([question_embedding]).astype(np.float32)\n",
        "faiss.normalize_L2(question_embedding)\n",
        "\n",
        "# 2. 인덱스에서 가장 유사한 문서 검색\n",
        "similarity_scores, indices = index.search(question_embedding, k=7)\n",
        "# → 가장 유사한 7개 문서의 점수와 인덱스 반환\n",
        "\n",
        "# 3. 7개의 검색 결과 중 카테고리가 \"Billing\"인 문서만 추려내기\n",
        "results = []\n",
        "category_filter = \"Billing\"\n",
        "\n",
        "for i, (score, idx) in enumerate(zip(similarity_scores[0], indices[0])):\n",
        "    if idx < len(knowledge_base_documents):\n",
        "        doc = knowledge_base_documents[idx]\n",
        "        \n",
        "        # Apply category filter if specified\n",
        "        if category_filter and doc.metadata.get('category') != category_filter:\n",
        "            continue\n",
        "        \n",
        "        results.append({\n",
        "            'content': doc.page_content,\n",
        "            'metadata': doc.metadata,\n",
        "            'score': float(score),\n",
        "            'rank': i + 1\n",
        "        })\n",
        "\n",
        "for result in results:\n",
        "    print(f\"문서 내용: {result['content'][:100]}...\")\n",
        "    print(f\"유사도 점수: {result['score']:.3f}\")\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "여기서의 과정을 활용하여 추후에 Tool을 만드는데에 활용해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 4: Web Search (Web Search Tool 준비)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1. Tavily\n",
        "\n",
        "지식 베이스로 가지고 있는 문서에도 존재하지 않고, 최신성 등의 이유로 웹 검색이 필요한 경우가 있을 수 있습니다.\n",
        "\n",
        "이를 위해서는 `Tavily`를 이용해 웹 서치를 구현하고 활용해보겠습니다.\n",
        "\n",
        "1. 검색은 `tavily_client.search` 메소드를 활용해보겠습니다.\n",
        "\n",
        "    - query: 우리가 궁금한 질문을 던집니다. (예: \"손흥민의 현재 소속팀은 어디야?\")\n",
        "\n",
        "    - search_depth: \"basic\"은 일반적인 검색, \"advanced\"는 더 깊이 있는 검색을 의미합니다. 여기서는 빠른 결과를 위해 basic을 사용합니다.\n",
        "\n",
        "    - max_results: 최대 몇 개의 검색 결과를 받을지 정합니다.\n",
        "\n",
        "2. 검색 결과를 딕셔너리 형태로 뽑은 뒤 정리해보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재미국 메이저 리그 사커의 로스앤젤레스 FC와 대한민국 축구 국가대표팀소속으로 활동하고 있으며 대한민국 축구 국가대표팀의 주장을 맡고 있다.\n",
            "https://ko.wikipedia.org/wiki/손흥민\n",
            "0.8742601\n",
            "\n",
            "대한민국 국적의 로스앤젤레스 FC 소속 축구 선수. 주 포지션은 윙어.대한민국 국가대표팀의 주장을 맡고 있다. 대표적으로 발롱도르 후보 2회, FIFPro 월드 XI 후보 2회\n",
            "https://namu.wiki/w/손흥민\n",
            "0.85567063\n",
            "\n",
            "Aug 10, 2025—손흥민이 새 소속팀인LAFC의 원정 경기 교체 명단에 포함됐다. LAFC ... 영국 매체 '기브미스포츠'는 \"손흥민은 현재 MLS 연봉 3위인 세르히오\n",
            "https://sports.news.nate.com/view/20250810n02077\n",
            "0.8361405\n",
            "\n",
            "Aug 14, 2025—전소속팀토트넘과 10년 동행에 마침표를 찍고 MLS에 진출한손흥민은지난 10일소속팀LA FC 유니폼을 입고 시카고를 상대로 원정 데뷔전을 치뤘다.\n",
            "https://www.mhnse.com/news/articleView.html?idxno=441507\n",
            "0.8319231\n",
            "\n",
            "손흥민은 LAFC 구단을 넘어 미국 메이저리그사커(MLS) 역사 전체를 돌아봐도 한손에 꼽힐 만한 대형 스타다. 이후 위고 요리스, 올리비에 지루 등 유명 스타 선수들을 영입한 LAFC는 2022시즌 창단 8년 만에 MLS컵 우승을 달성했고 지난 2024시즌에는 US 오픈컵 우승도 차지하며 떠오르는 MLS 강호로 자리잡았다. 손흥민의 전 팀 동료 위고 요리스가 현재 LAFC 부주장이다. MLS의 대회방식은](/news/articleView.html? * [[나성으로 간 손흥민] ③ 베컴 메시 손흥민 레츠고, 지정선수 제도의 역사](/news/articleView.html? * [[손흥민, 안녕 런던] ③ ‘127’에서 끝, 이제 볼 수 없는 SON의 PL골](/news/articleView.html? [[멕시코전 라인업] ‘손흥민 벤치·카스트로프 선발’ 홍명보호, 멕시코전 선발 명단 ‘대거 교체’… 9명 바꿨다](/news/articleView.html? ‘한 경기 3명 다친’ PSG, 개막 4연승에도 웃지 못했다… 뎀벨레·두에 이어 흐비차·베랄두 아웃](/news/articleView.html? '홍철 동점골, 구본철 결승골'로 첫 ACLE서 감격적 역전승!](/news/articleView.html? 강원은 1-1 팽팽한 접전 중](/news/articleView.html?\n",
            "https://www.footballist.co.kr/news/articleView.html?idxno=199967\n",
            "0.8116913\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tavily import TavilyClient\n",
        "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "tavily_client = TavilyClient(api_key=tavily_api_key)\n",
        "\n",
        "query = \"손흥민의 현재 소속팀은 어디야?\"\n",
        "max_results = 5\n",
        "response = tavily_client.search(\n",
        "    query=query,\n",
        "    search_depth=\"basic\",\n",
        "    max_results=max_results,\n",
        "    include_domains=[],\n",
        "    exclude_domains=[]\n",
        ")\n",
        "\n",
        "results = []\n",
        "for result in response.get('results', []):\n",
        "    results.append({\n",
        "        'title': result.get('title', ''),\n",
        "        'url': result.get('url', ''),\n",
        "        'content': result.get('content', ''),\n",
        "        'score': result.get('score', 0.0)\n",
        "    })\n",
        "\n",
        "for result in results:\n",
        "    print(result['content'])\n",
        "    print(result['url'])\n",
        "    print(result['score'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이처럼 웹서치를 활용해 LLM의 답변에 활용할 수 있는 지식을 더해줄 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 5: LangGraph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Section2: Upstage의 모델을 활용하여 텍스트 생성(Chat), 임베딩, LangChain의 `ChatUpstage`\n",
        "- Section3: RAG Tool 준비를 위해 VectorStore 만들기\n",
        "- Section4: Web Search Tool 준비를 위해 Tavily 활용하기\n",
        "\n",
        "를 배웠습니다. 지금은 배운 것들을 활용해 LLM에게 Tool로 쥐어주고 Agent를 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1. Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Section3, 4에서 준비한 문서검색용 Tool과 Web Search Tool을 만들어보겠습니다.\n",
        "- LangGraph에서 Tool로 활용하기 위해서는 다음의 작업이 필요합니다.\n",
        "    1. 실제 Tool 구현 (Python 함수의 형태로 구현합니다.)\n",
        "    2. Tool임을 명시하기 위해 @tool 데코레이터를 붙여줍니다.\n",
        "    3. LLM에게 해당 Tool을 사용할 수 있다는 것을 알려주기 위해 `bind_tools` 해줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1.1 `search_knowledge_base`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 벡터 유사도 기반으로 내부에 구성된 지식 베이스에서 검색을 수행하는 함수입니다.\n",
        "- 내부적으로는 `_get_embeddings`라는 helper function의 도움을 받습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
        "    base_url=\"https://api.upstage.ai/v1\"\n",
        ")\n",
        "\n",
        "def _get_embeddings(client: OpenAI, texts: List[str], mode: str = \"query\") -> List[List[float]]:\n",
        "    \"\"\"Get embeddings using Solar embedding model.\n",
        "    \n",
        "    Args:\n",
        "        client: OpenAI client configured for Upstage API\n",
        "        texts: List of input strings\n",
        "        mode: \"query\" or \"passage\"\n",
        "        \n",
        "    Returns:\n",
        "        List of embedding vectors\n",
        "    \"\"\"\n",
        "    if mode == \"query\":\n",
        "        model = \"embedding-query\"\n",
        "    elif mode == \"passage\":\n",
        "        model = \"embedding-passage\"\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'query' or 'passage'\")\n",
        "    \n",
        "    response = client.embeddings.create(\n",
        "        model=model,\n",
        "        input=texts\n",
        "    )\n",
        "    return [embedding.embedding for embedding in response.data]\n",
        "\n",
        "@tool\n",
        "def search_knowledge_base(query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Search the internal knowledge base using vector similarity.\"\"\"\n",
        "    if query is None or not str(query).strip():\n",
        "        return [{\"error\": \"query is required\"}]\n",
        "\n",
        "    client = OpenAI(\n",
        "        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
        "        base_url=\"https://api.upstage.ai/v1\"\n",
        "    )\n",
        "    q_emb = _get_embeddings(client, [query], mode=\"query\")[0]\n",
        "    q_vec = np.array([q_emb]).astype(np.float32)\n",
        "    faiss.normalize_L2(q_vec)\n",
        "\n",
        "    scores, idxs = index.search(q_vec, k=max(1, int(top_k)))\n",
        "\n",
        "    results = []\n",
        "    for i, (score, idx) in enumerate(zip(scores[0], idxs[0])):\n",
        "        if idx < len(knowledge_base_documents):\n",
        "            doc = knowledge_base_documents[idx]\n",
        "        \n",
        "            result = {\n",
        "                \"content\": doc.page_content,\n",
        "                \"score\": float(score),\n",
        "                \"topic\": doc.metadata.get('topic', 'General'),\n",
        "                \"category\": doc.metadata.get('category', 'N/A'),\n",
        "                \"index\": int(idx),\n",
        "                \"rank\": i + 1\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    if not results:\n",
        "        return [{\"message\": \"No relevant information found in the knowledge base.\"}]\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위와 같이 Tool로 구성하면, `invoke` 메소드를 활용해 결과를 확인 할 수 있습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': \"To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\", 'score': 0.47400760650634766, 'topic': 'Password Reset', 'category': 'Account', 'index': 0, 'rank': 1}, {'content': 'Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.', 'score': 0.26424017548561096, 'topic': 'Security', 'category': 'Account', 'index': 5, 'rank': 2}, {'content': 'Data export is available for all plans. Go to Account Settings > Data Export to request your data. The export will be emailed to you within 24 hours and includes all your account data in JSON format.', 'score': 0.2117936909198761, 'topic': 'Data Export', 'category': 'Account', 'index': 4, 'rank': 3}]\n",
            "content: To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\n",
            "score: 0.47400760650634766\n",
            "topic: Password Reset\n",
            "category: Account\n",
            "index: 0\n",
            "rank: 1\n"
          ]
        }
      ],
      "source": [
        "results = search_knowledge_base.invoke(\"I forgot my password!\")\n",
        "print(results)\n",
        "\n",
        "for k, v in results[0].items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1.1 `web_search`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- web_search`: 웹 검색을 수행하는 함수입니다.\n",
        "- 내부적으로는 `_rewrite_query_for_search`라는 helper function의 도움을 받습니다.\n",
        "    - `web_search` 함수에서 `rewrite_mode`가 True로 설정돼있을때, 사용자의 쿼리를  LLM을 활용해 재작성합니다.\n",
        "    - 안정적인 결과 출력을 위해 위에서 배운 `response_format`을 활용한 구조화 된 출력을 활용했습니다.\n",
        "    - `datetime.now()`를 활용해 현재 날짜를 확인할 수 있게 했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
        "    base_url=\"https://api.upstage.ai/v1\"\n",
        ")\n",
        "\n",
        "def _rewrite_query_for_search(query: str) -> str:\n",
        "    \"\"\"Use LLM to rewrite customer question into optimal search query.\n",
        "    \n",
        "    Args:\n",
        "        query: Original search query\n",
        "        \n",
        "    Returns:\n",
        "        LLM-optimized search query\n",
        "    \"\"\"\n",
        "    try:\n",
        "        \n",
        "        current_time = datetime.now()\n",
        "        current_date = current_time.strftime(\"%Y-%m-%d\")\n",
        "        \n",
        "        rewrite_prompt = f\"\"\"\n",
        "        <role>\n",
        "        You are an expert search query optimizer. Your task is to transform verbose, conversational user questions into concise, keyword-driven search queries that will yield the best possible results from a web search engine.\n",
        "        </role>\n",
        "\n",
        "        <instructions>\n",
        "        1.  **Identify Core Intent:** Analyze the user's question to understand their fundamental goal.\n",
        "        2.  **Extract Key Entities:** Pull out essential keywords, names, locations, constraints (like budget or time), and concepts.\n",
        "        3.  **Remove Filler:** Discard conversational fluff (e.g., \"I was wondering\", \"can you help me\", \"please\", \"I think\").\n",
        "        4.  **Synthesize Keywords:** Combine the extracted entities into a logical, concise search string.\n",
        "        5.  **Keep it Brief:** The final query should ideally be under 10 words.\n",
        "        6.  **IMPORTANT:** Return ONLY the search query, no explanations, no tags, no thinking process.\n",
        "        7.  **Time Context:** If user asks time-specific question, use current time information (current date: {current_date}).\n",
        "        </instructions>\n",
        "\n",
        "        <example>\n",
        "        <user_question>\n",
        "        I'm thinking of going to Europe this winter, maybe for like a week. I'm on a budget but I still want to see some cool historical stuff. Can you give me some recommendations?\n",
        "        </user_question>\n",
        "        <rewritten_query>\n",
        "        best budget winter destinations Europe historical sites one week\n",
        "        </rewritten_query>\n",
        "        </example>\n",
        "\n",
        "        <user_question>\n",
        "        {query}\n",
        "        </user_question>\n",
        "\n",
        "        <output_format>\n",
        "        Provide ONLY the rewritten search query as a single line of text. Do not add any introductory phrases like \"Here is the query:\".\n",
        "        And also DO NOT PROVIDE THE THINKING STEPS, just provide the rewritten query.\n",
        "        </output_format>\n",
        "\n",
        "        <rewritten_query>\n",
        "        \"\"\"\n",
        "    \n",
        "        response_format = {\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"search_query_suggestions\",\n",
        "            \"strict\": True,\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"rewritten_query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The most relevant search query for this inquiry\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"rewritten_query\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "        response = client.chat.completions.create(\n",
        "            model=\"solar-pro2\",\n",
        "            messages=[{\"role\": \"system\", \"content\": rewrite_prompt}],\n",
        "            # max_tokens=100,\n",
        "            response_format=response_format\n",
        "        )\n",
        "        \n",
        "        result = json.loads(response.choices[0].message.content)\n",
        "        \n",
        "        # Return the primary query as the main result\n",
        "        return result[\"rewritten_query\"]\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️ LLM query rewrite failed: {str(e)}, using original query\")\n",
        "        return query\n",
        "\n",
        "\n",
        "@tool\n",
        "def web_search(query: str, max_results: int = 3, rewrite_mode: bool = True) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Search the web for relevant information about a customer query.\n",
        "    \n",
        "    This tool searches the internet to find current information that can help\n",
        "    answer customer questions, especially for technical issues or general topics\n",
        "    not covered in the internal knowledge base.\n",
        "    \n",
        "    Args:\n",
        "        query: The customer's question or search query\n",
        "        max_results: Maximum number of search results to return (default: 3)\n",
        "        rewrite_mode: Whether to use LLM to optimize the search query (default: True)\n",
        "        \n",
        "    Returns:\n",
        "        List of dictionaries containing structured web search results with scores and metadata\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize Tavily client\n",
        "        tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
        "        \n",
        "        # Optionally rewrite query for better search results\n",
        "        search_query = query\n",
        "        if rewrite_mode:\n",
        "            search_query = _rewrite_query_for_search(query)\n",
        "        print(f\"Search with the query: {search_query}\")\n",
        "        \n",
        "        # Search the web\n",
        "        response = tavily_client.search(\n",
        "            query=search_query,\n",
        "            search_depth=\"basic\",\n",
        "            max_results=max_results,\n",
        "            include_domains=[],\n",
        "            exclude_domains=[]\n",
        "        )\n",
        "        \n",
        "        if not response.get('results'):\n",
        "            return [{\"message\": \"No relevant web search results found.\"}]\n",
        "        \n",
        "        # Return structured results\n",
        "        results = []\n",
        "        for i, result in enumerate(response['results'], 1):\n",
        "            structured_result = {\n",
        "                \"title\": result.get('title', 'Untitled'),\n",
        "                \"content\": result.get('content', 'No content available'),\n",
        "                \"url\": result.get('url', 'No URL'),\n",
        "                \"score\": float(result.get('score', 0.0)),\n",
        "                \"rank\": i,\n",
        "                \"query\": search_query\n",
        "            }\n",
        "            results.append(structured_result)\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        return [{\"error\": f\"Web search error: {str(e)}\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search with the query: 손흥민 현재 소속 팀\n",
            "[{'title': '손흥민 - 위키백과, 우리 모두의 백과사전', 'content': '현재 미국 메이저 리그 사커의 로스앤젤레스 FC와 대한민국 축구 국가대표팀 소속으로 활동하고 있으며 대한민국 축구 국가대표팀의 주장을 맡고 있다.', 'url': 'https://ko.wikipedia.org/wiki/%EC%86%90%ED%9D%A5%EB%AF%BC', 'score': 0.8827621, 'rank': 1, 'query': '손흥민 현재 소속 팀'}, {'title': '손흥민 - 나무위키', 'content': '대한민국 국적의 로스앤젤레스 FC 소속 축구 선수. 주 포지션은 윙어. 대한민국 국가대표팀의 주장을 맡고 있다. 대표적으로 발롱도르 후보 2회, FIFPro 월드 XI 후보 2회', 'url': 'https://namu.wiki/w/%EC%86%90%ED%9D%A5%EB%AF%BC', 'score': 0.8364614, 'rank': 2, 'query': '손흥민 현재 소속 팀'}, {'title': '\"손흥민 존재감, 메시와 경쟁 가능…美 최초 기록도 세웠어\" MLS ...', 'content': '손흥민의 소속팀 LAFC는 22일(한국시간) 미국 캘리포니아주 로스앤젤레스 ... 부앙가와 메시는 이번 시즌 현재까지 나란히 22골을 기록 중이다.', 'url': 'https://v.daum.net/v/20250922222446435', 'score': 0.8335554, 'rank': 3, 'query': '손흥민 현재 소속 팀'}]\n",
            "Search with the query: 손흥민 current team 2025-09\n",
            "[{'title': 'Heung-min Son - Player profile 2025 - Transfermarkt', 'content': 'Heung-min Son, 33, from Korea, South ➤ Los Angeles FC, since 2025 ➤ Left Winger ➤ Market value: €20.00m ➤ * 08.07.1992 in Chuncheon,', 'url': 'https://www.transfermarkt.com/heung-min-son/profil/spieler/91845', 'score': 0.7180613, 'rank': 1, 'query': '손흥민 current team 2025-09'}, {'title': '손흥민/클럽 경력/2025 시즌 - 나무위키', 'content': '이로써 2024-25 시즌이 손흥민과 토트넘의 10년 동행에 마침표를 찍는 해가 되었고 프리시즌 뉴캐슬과의 경기가 토트넘 소속으로 뛰는 마지막 경기[1]가 되었다. 한 가지', 'url': 'https://namu.wiki/w/%EC%86%90%ED%9D%A5%EB%AF%BC/%ED%81%B4%EB%9F%BD%20%EA%B2%BD%EB%A0%A5/2025%20%EC%8B%9C%EC%A6%8C', 'score': 0.65252984, 'rank': 2, 'query': '손흥민 current team 2025-09'}, {'title': '손흥민 - 위키백과, 우리 모두의 백과사전', 'content': '손흥민(孫興慜, 1992년 7월 8일~)은 대한민국의 축구 선수로, 포지션은 공격수이다. 현재 미국 메이저 리그 사커의 로스앤젤레스 FC와 대한민국 축구 국가대표팀 소속', 'url': 'https://ko.wikipedia.org/wiki/%EC%86%90%ED%9D%A5%EB%AF%BC', 'score': 0.57236487, 'rank': 3, 'query': '손흥민 current team 2025-09'}]\n",
            "Search with the query: 손흥민 현재 소속팀\n",
            "[{'title': '손흥민 - 위키백과, 우리 모두의 백과사전', 'content': '현재 미국 메이저 리그 사커의 로스앤젤레스 FC와 대한민국 축구 국가대표팀 소속으로 활동하고 있으며 대한민국 축구 국가대표팀의 주장을 맡고 있다.', 'url': 'https://ko.wikipedia.org/wiki/%EC%86%90%ED%9D%A5%EB%AF%BC', 'score': 0.8793233, 'rank': 1, 'query': '손흥민 현재 소속팀'}, {'title': '손흥민 - 나무위키', 'content': '대한민국 국적의 로스앤젤레스 FC 소속 축구 선수. 주 포지션은 윙어. 대한민국 국가대표팀의 주장을 맡고 있다. 대표적으로 발롱도르 후보 2회, FIFPro 월드 XI 후보 2회', 'url': 'https://namu.wiki/w/%EC%86%90%ED%9D%A5%EB%AF%BC', 'score': 0.8302782, 'rank': 2, 'query': '손흥민 현재 소속팀'}, {'title': \"[나성으로 간 손흥민] ① '손흥민 새 소속팀' LAFC는 어떤 클럽일까?\", 'content': \"손흥민은 LAFC 구단을 넘어 미국 메이저리그사커(MLS) 역사 전체를 돌아봐도 한손에 꼽힐 만한 대형 스타다. 이후 위고 요리스, 올리비에 지루 등 유명 스타 선수들을 영입한 LAFC는 2022시즌 창단 8년 만에 MLS컵 우승을 달성했고 지난 2024시즌에는 US 오픈컵 우승도 차지하며 떠오르는 MLS 강호로 자리잡았다. 손흥민의 전 팀 동료 위고 요리스가 현재 LAFC 부주장이다. MLS의 대회방식은](/news/articleView.html? * [[나성으로 간 손흥민] ③ 베컴 메시 손흥민 레츠고, 지정선수 제도의 역사](/news/articleView.html? * [[손흥민, 안녕 런던] ③ ‘127’에서 끝, 이제 볼 수 없는 SON의 PL골](/news/articleView.html? [[멕시코전 라인업] ‘손흥민 벤치·카스트로프 선발’ 홍명보호, 멕시코전 선발 명단 ‘대거 교체’… 9명 바꿨다](/news/articleView.html? ‘한 경기 3명 다친’ PSG, 개막 4연승에도 웃지 못했다… 뎀벨레·두에 이어 흐비차·베랄두 아웃](/news/articleView.html? '홍철 동점골, 구본철 결승골'로 첫 ACLE서 감격적 역전승!](/news/articleView.html? 강원은 1-1 팽팽한 접전 중](/news/articleView.html?\", 'url': 'https://www.footballist.co.kr/news/articleView.html?idxno=199967', 'score': 0.8156003, 'rank': 3, 'query': '손흥민 현재 소속팀'}]\n"
          ]
        }
      ],
      "source": [
        "for _ in range(3):\n",
        "    results = web_search.invoke(\"손흥민이 현재 뛰고 있는 팀은?\")\n",
        "    print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 *Prebuilt* ReAct Agent Graph 구현하기\n",
        "\n",
        "이제 Tool이 완성됐으니, Graph를 구현해 볼 차례입니다.\n",
        "\n",
        "우선 Node와 Edge를 직접 연결해서 Graph를 만들기전에, LangGraph에 직접 구현이 돼있는(`prebuilt`) ReAct 에이전트를 살펴보겠습니다.\n",
        "\n",
        "- ReAct Agent [[paper](https://arxiv.org/abs/2210.03629)]\n",
        "    - ReAct는 LLM의 내부적인 '사고(Reasoning)' 능력과, 외부 세계와 상호작용하는 **'행동(Action)'**을 결합시킨 강력한 에이전트 프레임워크입니다. 에이전트는 먼저 문제 해결 계획을 세우고(Thought), 그에 따라 도구를 사용한 뒤(Action), 그 결과를 관찰하여(Observation) 다음 행동을 결정하는 순환적 과정을 거칩니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위에서 구현한 Tool들도 하나의 노드 역할을 하게 되는데요. 여기서는 Tool이 작업되는 노드도 `prebuilt`의 `ToolNode`를 활용해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOOLS = [search_knowledge_base, web_search]\n",
        "rag_tool_node = ToolNode(TOOLS)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Example: Simple LangGraph Agent with RAG Tools\n",
        "# ------------------------------------------------------------\n",
        "def create_simple_agent():\n",
        "    \"\"\"Create a simple LangGraph agent with RAG tools.\"\"\"\n",
        "\n",
        "\n",
        "    checkpointer = InMemorySaver()\n",
        "    \n",
        "    # Initialize LLM\n",
        "    llm = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
        "    \n",
        "    # Create agent with tools\n",
        "    agent = create_react_agent(\n",
        "        model=llm,\n",
        "        tools=TOOLS,\n",
        "        prompt=\"You are a helpful customer support agent. Use the available tools to search the knowledge base and web for information to help customers.\",\n",
        "        checkpointer=checkpointer\n",
        "    )\n",
        "    \n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "react_agent = create_simple_agent()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "display(Image(react_agent.get_graph().draw_mermaid_png()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- LangGraph에서 구현한 ReAct Agent는 아래와 같은 모습을 하고 있습니다.\n",
        "    - \"agent\"라고 붙은 LLM **노드** 에서 사용자의 질의를 처리합니다.\n",
        "        - agent 노드에서는 \\_\\_end\\_\\_ 노드와 tools 노드 방향으로 향하는 점선의 edge가 있습니다. 이 edge가 바로 conditional edge 입니다.\n",
        "            - tools 활용이 필요하면 tools로, 그렇지 않고 답변을 마칠 수 있으면 \\_\\_end\\_\\_로 갈 수 있게 돼있습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 이 ReAct Agent에 질의를 한번 해보겠습니다. \n",
        "\n",
        "(우선 간단하게 메모리 관리를 위해 LangGraph의 `InMemorySaver`를 설정하고 `config`를 설정해줬습니다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search with the query: 회사 API 접속 문제 해결 방법\n",
            "[HumanMessage(content='우리 회사 API에 접속이 잘 안되는데.', additional_kwargs={}, response_metadata={}, id='849d77a9-c9ba-49a6-88bc-290cb87a6582'), AIMessage(content='[API 접속 문제를 해결하기 위해 내부 지식 베이스에서 관련 해결 방법을 검색하고, 추가로 웹에서 최신 정보를 확인하기 위해 두 함수를 호출했습니다. 내부 지식 베이스에는 회사 특정 API 문제 해결 절차가 있을 수 있으며, 웹 검색은 일반적인 API 접속 문제 해결 방법을 제공할 수 있어 둘 다 필수적입니다.]  \\n\\n추가로 다음 정보를 제공해 주시면 더 정확한 도움을 드릴 수 있습니다:  \\n1. 어떤 API 엔드포인트에 접속하시려고 하나요?  \\n2. 어떤 오류 메시지가 표시되나요? (예: 404 Not Found, 500 Internal Server Error 등)  \\n3. 접속 시도 시 사용한 클라이언트/도구(Postman, cURL 등)와 요청 예시(헤더/바디 포함)가 있나요?', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-f9ff751235ea444383300e284ff0bb90', 'function': {'arguments': '{\"query\": \"\\\\ud68c\\\\uc0ac API \\\\uc811\\\\uc18d \\\\ubb38\\\\uc81c \\\\ud574\\\\uacb0 \\\\ubc29\\\\ubc95\"}', 'name': 'search_knowledge_base'}, 'type': 'function'}, {'id': 'chatcmpl-tool-5c753ae623c14a519ec47067eaf7f0a1', 'function': {'arguments': '{\"query\": \"\\\\ud68c\\\\uc0ac API \\\\uc811\\\\uc18d \\\\ubb38\\\\uc81c \\\\ud574\\\\uacb0 \\\\ubc29\\\\ubc95\"}', 'name': 'web_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 751, 'total_tokens': 926, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--f280a2c1-1827-4942-88bd-8ed7753f3d0b-0', tool_calls=[{'name': 'search_knowledge_base', 'args': {'query': '회사 API 접속 문제 해결 방법'}, 'id': 'chatcmpl-tool-f9ff751235ea444383300e284ff0bb90', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': '회사 API 접속 문제 해결 방법'}, 'id': 'chatcmpl-tool-5c753ae623c14a519ec47067eaf7f0a1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 751, 'output_tokens': 175, 'total_tokens': 926, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"content\": \"To integrate our API, use the base URL https://api.ourcompany.com/v1. Authentication requires an API key in the Authorization header. Example: Authorization: Bearer your_api_key_here\", \"score\": 0.3284298777580261, \"topic\": \"API Integration\", \"category\": \"Technical\", \"index\": 3, \"rank\": 1}, {\"content\": \"Our API rate limits are 1000 requests per hour for Basic plans, 5000 for Premium, and 10000 for Enterprise. If you exceed these limits, you\\'ll receive a 429 status code. Consider upgrading your plan for higher limits.\", \"score\": 0.25630033016204834, \"topic\": \"API Limits\", \"category\": \"Technical\", \"index\": 2, \"rank\": 2}, {\"content\": \"Our service status page is available at status.ourcompany.com. We post real-time updates about any service disruptions, maintenance windows, or performance issues.\", \"score\": 0.2561466097831726, \"topic\": \"Service Status\", \"category\": \"Technical\", \"index\": 7, \"rank\": 3}]', name='search_knowledge_base', id='088f4962-cb15-4fdf-bda6-c9555630a22a', tool_call_id='chatcmpl-tool-f9ff751235ea444383300e284ff0bb90'), ToolMessage(content='[{\"title\": \"REST API의 일반적인 문제 해결 - AppMaster\", \"content\": \"REST API의 일반적인 문제 해결 · 1. 일반적인 REST API 문제 이해 · 2. 인증 및 권한 부여 문제 · 3. 속도 제한 및 조절 · 4. CORS 및 교차 출처 요청 · 5. 효율적인 페이지\", \"url\": \"https://appmaster.io/ko/blog/rest-apiyi-ilbanjeogin-munje-haegyeol\", \"score\": 0.35367426, \"rank\": 1, \"query\": \"회사 API 접속 문제 해결 방법\"}, {\"title\": \"API 문제에 대응 - New Relic docs\", \"content\": \"문제가 있는 API 호출은 작은 재고 사고부터 사이트가 결제 프로세서와 통신할 수 없는 코드 레드 상황까지 발생할 수 있습니다. 어쩌면 외부 API 문제가 아니라 내부 인벤토리 API 문제일 수도 있습니다. 이 튜토리얼 시리즈에서는 문제가 있는 API 상호 작용을 식별하는 방법과 New Relic 플랫폼을 사용하여 이를 해결하는 방법을 보여줍니다. * 외부 서비스 UI를 통해 문제가 있는 API 식별 위 문서의 추가 단계를 완료한 후 **one.newrelic.com)** > 앱 선택 > **External services** [외부 서비스] 로 이동하세요.API 및 외부 서비스 흐름에 대한 데이터가 표시되어야 합니다. 이제 애플리케이션이 API 및 기타 외부 서비스와 상호 작용하는 방식을 추적할 수 있습니다. 해당 정보를 사용하여 문제를 일으키는 API 또는 외부 서비스를 식별해 보겠습니다. 이는 모든 자체 서비스와 외부 서비스 또는 API 간의 관계를 보여줍니다.\", \"url\": \"https://docs.newrelic.com/kr/docs/tutorial-troubleshoot-external-services-apis/respond-external/\", \"score\": 0.33160707, \"rank\": 2, \"query\": \"회사 API 접속 문제 해결 방법\"}, {\"title\": \"API 실패란 무엇인가? 6가지 원인과 해결 방법 - Apidog\", \"content\": \"API 실패는 디지털 대화를 방해하여 사용자 경험, 운영 효율성 및 비즈니스 결과에 영향을 미치는 문제를 일으킬 수 있습니다. Image 2: API 실패란 무엇인가? API 오류는 디지털 대화를 방해하여 사용자 경험, 운영 효율성 및 비즈니스 결과에 영향을 미치는 문제의 연쇄를 초래할 수 있습니다. Apidog는 API 오류를 선제적으로 극복할 수 있도록 도와주며, 최첨단 실시간 모니터링 및 신속한 진단 능력으로 원활한 디지털 운영을 보장합니다. Image 3: API 오류 예시 API 오류는 여러 출처에서 발생할 수 있습니다. API 오류는 디지털 환경의 불가피한 부분이지만, 면밀한 모니터링, 신속한 대응 및 지속적인 개선 관행을 통해 그 영향을 크게 줄일 수 있습니다. API 오류의 일반적인 원인을 이해하고 해결을 위한 체계적인 접근을 채택함으로써, 개발자와 기업은 디지털 서비스의 회복력과 신뢰성을 향상시킬 수 있습니다.\", \"url\": \"https://apidog.com/kr/blog/what-is-api-failure-2/\", \"score\": 0.32633632, \"rank\": 3, \"query\": \"회사 API 접속 문제 해결 방법\"}]', name='web_search', id='6d0f46ac-ac93-46c3-a3fb-72c94dc2fcde', tool_call_id='chatcmpl-tool-5c753ae623c14a519ec47067eaf7f0a1'), AIMessage(content='API 접속 문제를 해결하기 위해 다음 단계를 확인해 주세요:\\n\\n### 1. **기본 확인 사항**\\n   - **API 엔드포인트 URL**: `https://api.ourcompany.com/v1`을 사용 중인지 확인하세요.\\n   - **인증 헤더**: 요청 헤더에 `Authorization: Bearer [유효한_API_키]`가 포함되어 있는지 확인하세요.\\n   - **서비스 상태**: [상태 페이지](https://status.ourcompany.com)에서 현재 API 서비스 상태를 확인해 주세요.\\n\\n### 2. **일반적인 문제 해결 방법**\\n   - **인증 오류**: API 키가 유효한지, 만료되지 않았는지 확인하세요.  \\n     (예: `401 Unauthorized` 오류 발생 시)\\n   - **속도 제한**: 요금제별 요청 한도를 초과했는지 확인하세요.  \\n     (예: `429 Too Many Requests` 오류 발생 시)\\n   - **네트워크 문제**: 방화벽 또는 프록시 설정으로 인해 차단되지 않았는지 확인하세요.\\n   - **CORS 문제**: 브라우저에서 호출 시 `CORS` 오류가 발생할 수 있습니다. 백엔드 또는 프론트엔드 설정을 검토하세요.\\n\\n### 3. **추가 조치**\\n   - **요청 예시**:  \\n     ```http\\n     GET https://api.ourcompany.com/v1/endpoint\\n     Authorization: Bearer your_api_key_here\\n     Content-Type: application/json\\n     ```\\n   - **도구 활용**: Postman 또는 `curl`로 테스트하여 클라이언트 측 문제인지 확인하세요.  \\n     (예: `curl -H \"Authorization: Bearer your_api_key\" https://api.ourcompany.com/v1/endpoint`)\\n\\n### 4. **오류 메시지별 대응**\\n   - **404 Not Found**: 엔드포인트 URL이 정확한지, 경로가 변경되지 않았는지 확인하세요.\\n   - **500 Internal Server Error**: 일시적인 서버 오류일 수 있습니다. 잠시 후 재시도하거나 상태 페이지를 확인하세요.\\n   - **연결 시간 초과**: 네트워크 지연 또는 DNS 문제일 수 있습니다. `ping` 또는 `traceroute`로 네트워크 상태를 진단하세요.\\n\\n### 5. **문의 사항**\\n   - 위 단계로 해결되지 않을 경우, 다음 정보를 제공해 주시면 더 정확히 도와드릴 수 있습니다:\\n     - 발생한 **정확한 오류 메시지** (예: HTTP 상태 코드, 에러 본문)\\n     - 사용 중인 **API 엔드포인트** 및 **요청 예시** (헤더/바디 포함)\\n     - 문제 발생 **시간대** 및 **빈도** (지속적/간헐적인지)\\n\\n내부 지식 베이스와 웹 검색 결과를 종합해 일반적인 API 문제 해결 방법을 안내드렸습니다. 추가 정보가 있다면 더 구체적인 지원이 가능합니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 522, 'prompt_tokens': 1811, 'total_tokens': 2333, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6f974eff-e4e9-4aca-ae7b-133f4fddfe43-0', usage_metadata={'input_tokens': 1811, 'output_tokens': 522, 'total_tokens': 2333, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "response = react_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"우리 회사 API에 접속이 잘 안되는데.\"}]},\n",
        "    config  \n",
        ")\n",
        "print(response['messages'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 결과 확인을 위한 Helper Function 입니다. ##\n",
        "def pretty_print_conversation(messages):\n",
        "    \"\"\"Pretty print conversation flow with detailed step-by-step analysis.\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"�� CONVERSATION FLOW ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    step_counter = 1\n",
        "    \n",
        "    for i, message in enumerate(messages):\n",
        "        print(f\"\\n{'─'*60}\")\n",
        "        print(f\"📝 STEP {step_counter}: {message.__class__.__name__}\")\n",
        "        print(f\"{'─'*60}\")\n",
        "        \n",
        "        if isinstance(message, HumanMessage):\n",
        "            print(f\"👤 USER INPUT:\")\n",
        "            print(f\"   {message.content}\")\n",
        "            \n",
        "        elif isinstance(message, AIMessage):\n",
        "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "                print(f\"🤖 ASSISTANT DECISION:\")\n",
        "                print(f\"   💭 Reasoning: {message.content}\")\n",
        "                print(f\"\\n🔧 TOOL CALLS:\")\n",
        "                \n",
        "                for j, tool_call in enumerate(message.tool_calls):\n",
        "                    print(f\"   {j+1}. Tool: {tool_call['name']}\")\n",
        "                    print(f\"      Args: {tool_call['args']}\")\n",
        "                    print(f\"      ID: {tool_call['id']}\")\n",
        "            else:\n",
        "                print(f\"🤖 ASSISTANT RESPONSE:\")\n",
        "                print(f\"   {message.content}\")\n",
        "                \n",
        "        elif hasattr(message, 'name') and message.name:  # ToolMessage\n",
        "            print(f\"📚 TOOL EXECUTION RESULT:\")\n",
        "            print(f\"   Tool: {message.name}\")\n",
        "            print(f\"   Call ID: {message.tool_call_id}\")\n",
        "            print(f\"   Result:\")\n",
        "            print(f\"   {message.content}\")\n",
        "            \n",
        "        # Show metadata if available\n",
        "        if hasattr(message, 'response_metadata') and message.response_metadata:\n",
        "            metadata = message.response_metadata\n",
        "            if 'token_usage' in metadata:\n",
        "                tokens = metadata['token_usage']\n",
        "                print(f\"\\n�� TOKEN USAGE:\")\n",
        "                print(f\"   Input: {tokens.get('prompt_tokens', 0)}\")\n",
        "                print(f\"   Output: {tokens.get('completion_tokens', 0)}\")\n",
        "                print(f\"   Total: {tokens.get('total_tokens', 0)}\")\n",
        "        \n",
        "        step_counter += 1\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"✅ CONVERSATION ANALYSIS COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "def analyze_tool_usage(messages):\n",
        "    \"\"\"Analyze tool usage patterns in the conversation.\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🔍 TOOL USAGE ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    tool_calls = []\n",
        "    tool_results = []\n",
        "    \n",
        "    for message in messages:\n",
        "        if isinstance(message, AIMessage) and hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            for tool_call in message.tool_calls:\n",
        "                tool_calls.append({\n",
        "                    'name': tool_call['name'],\n",
        "                    'args': tool_call['args'],\n",
        "                    'reasoning': message.content\n",
        "                })\n",
        "        elif hasattr(message, 'name') and message.name:\n",
        "            tool_results.append({\n",
        "                'name': message.name,\n",
        "                'result': message.content,\n",
        "                'call_id': message.tool_call_id\n",
        "            })\n",
        "    \n",
        "    print(f\"\\n📊 SUMMARY:\")\n",
        "    print(f\"   Total Tool Calls: {len(tool_calls)}\")\n",
        "    print(f\"   Total Tool Results: {len(tool_results)}\")\n",
        "    \n",
        "    if tool_calls:\n",
        "        print(f\"\\n🔧 TOOL CALLS BREAKDOWN:\")\n",
        "        for i, call in enumerate(tool_calls, 1):\n",
        "            print(f\"   {i}. {call['name']}\")\n",
        "            print(f\"      Arguments: {call['args']}\")\n",
        "            print(f\"      Reasoning: {call['reasoning'][:100]}...\")\n",
        "    \n",
        "    if tool_results:\n",
        "        print(f\"\\n�� TOOL RESULTS BREAKDOWN:\")\n",
        "        for i, result in enumerate(tool_results, 1):\n",
        "            print(f\"   {i}. {result['name']}\")\n",
        "            print(f\"      Result Length: {len(result['result'])} characters\")\n",
        "            print(f\"      Preview: {result['result'][:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "아래 결과를 통해 대화의 흐름을 살펴보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "�� CONVERSATION FLOW ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "📝 STEP 1: HumanMessage\n",
            "────────────────────────────────────────────────────────────\n",
            "👤 USER INPUT:\n",
            "   우리 회사 API에 접속이 잘 안되는데.\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "📝 STEP 2: AIMessage\n",
            "────────────────────────────────────────────────────────────\n",
            "🤖 ASSISTANT DECISION:\n",
            "   💭 Reasoning: [API 접속 문제를 해결하기 위해 내부 지식 베이스에서 관련 해결 방법을 검색하고, 추가로 웹에서 최신 정보를 확인하기 위해 두 함수를 호출했습니다. 내부 지식 베이스에는 회사 특정 API 문제 해결 절차가 있을 수 있으며, 웹 검색은 일반적인 API 접속 문제 해결 방법을 제공할 수 있어 둘 다 필수적입니다.]  \n",
            "\n",
            "추가로 다음 정보를 제공해 주시면 더 정확한 도움을 드릴 수 있습니다:  \n",
            "1. 어떤 API 엔드포인트에 접속하시려고 하나요?  \n",
            "2. 어떤 오류 메시지가 표시되나요? (예: 404 Not Found, 500 Internal Server Error 등)  \n",
            "3. 접속 시도 시 사용한 클라이언트/도구(Postman, cURL 등)와 요청 예시(헤더/바디 포함)가 있나요?\n",
            "\n",
            "🔧 TOOL CALLS:\n",
            "   1. Tool: search_knowledge_base\n",
            "      Args: {'query': '회사 API 접속 문제 해결 방법'}\n",
            "      ID: chatcmpl-tool-f9ff751235ea444383300e284ff0bb90\n",
            "   2. Tool: web_search\n",
            "      Args: {'query': '회사 API 접속 문제 해결 방법'}\n",
            "      ID: chatcmpl-tool-5c753ae623c14a519ec47067eaf7f0a1\n",
            "\n",
            "�� TOKEN USAGE:\n",
            "   Input: 751\n",
            "   Output: 175\n",
            "   Total: 926\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "📝 STEP 3: ToolMessage\n",
            "────────────────────────────────────────────────────────────\n",
            "📚 TOOL EXECUTION RESULT:\n",
            "   Tool: search_knowledge_base\n",
            "   Call ID: chatcmpl-tool-f9ff751235ea444383300e284ff0bb90\n",
            "   Result:\n",
            "   [{\"content\": \"To integrate our API, use the base URL https://api.ourcompany.com/v1. Authentication requires an API key in the Authorization header. Example: Authorization: Bearer your_api_key_here\", \"score\": 0.3284298777580261, \"topic\": \"API Integration\", \"category\": \"Technical\", \"index\": 3, \"rank\": 1}, {\"content\": \"Our API rate limits are 1000 requests per hour for Basic plans, 5000 for Premium, and 10000 for Enterprise. If you exceed these limits, you'll receive a 429 status code. Consider upgrading your plan for higher limits.\", \"score\": 0.25630033016204834, \"topic\": \"API Limits\", \"category\": \"Technical\", \"index\": 2, \"rank\": 2}, {\"content\": \"Our service status page is available at status.ourcompany.com. We post real-time updates about any service disruptions, maintenance windows, or performance issues.\", \"score\": 0.2561466097831726, \"topic\": \"Service Status\", \"category\": \"Technical\", \"index\": 7, \"rank\": 3}]\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "📝 STEP 4: ToolMessage\n",
            "────────────────────────────────────────────────────────────\n",
            "📚 TOOL EXECUTION RESULT:\n",
            "   Tool: web_search\n",
            "   Call ID: chatcmpl-tool-5c753ae623c14a519ec47067eaf7f0a1\n",
            "   Result:\n",
            "   [{\"title\": \"REST API의 일반적인 문제 해결 - AppMaster\", \"content\": \"REST API의 일반적인 문제 해결 · 1. 일반적인 REST API 문제 이해 · 2. 인증 및 권한 부여 문제 · 3. 속도 제한 및 조절 · 4. CORS 및 교차 출처 요청 · 5. 효율적인 페이지\", \"url\": \"https://appmaster.io/ko/blog/rest-apiyi-ilbanjeogin-munje-haegyeol\", \"score\": 0.35367426, \"rank\": 1, \"query\": \"회사 API 접속 문제 해결 방법\"}, {\"title\": \"API 문제에 대응 - New Relic docs\", \"content\": \"문제가 있는 API 호출은 작은 재고 사고부터 사이트가 결제 프로세서와 통신할 수 없는 코드 레드 상황까지 발생할 수 있습니다. 어쩌면 외부 API 문제가 아니라 내부 인벤토리 API 문제일 수도 있습니다. 이 튜토리얼 시리즈에서는 문제가 있는 API 상호 작용을 식별하는 방법과 New Relic 플랫폼을 사용하여 이를 해결하는 방법을 보여줍니다. * 외부 서비스 UI를 통해 문제가 있는 API 식별 위 문서의 추가 단계를 완료한 후 **one.newrelic.com)** > 앱 선택 > **External services** [외부 서비스] 로 이동하세요.API 및 외부 서비스 흐름에 대한 데이터가 표시되어야 합니다. 이제 애플리케이션이 API 및 기타 외부 서비스와 상호 작용하는 방식을 추적할 수 있습니다. 해당 정보를 사용하여 문제를 일으키는 API 또는 외부 서비스를 식별해 보겠습니다. 이는 모든 자체 서비스와 외부 서비스 또는 API 간의 관계를 보여줍니다.\", \"url\": \"https://docs.newrelic.com/kr/docs/tutorial-troubleshoot-external-services-apis/respond-external/\", \"score\": 0.33160707, \"rank\": 2, \"query\": \"회사 API 접속 문제 해결 방법\"}, {\"title\": \"API 실패란 무엇인가? 6가지 원인과 해결 방법 - Apidog\", \"content\": \"API 실패는 디지털 대화를 방해하여 사용자 경험, 운영 효율성 및 비즈니스 결과에 영향을 미치는 문제를 일으킬 수 있습니다. Image 2: API 실패란 무엇인가? API 오류는 디지털 대화를 방해하여 사용자 경험, 운영 효율성 및 비즈니스 결과에 영향을 미치는 문제의 연쇄를 초래할 수 있습니다. Apidog는 API 오류를 선제적으로 극복할 수 있도록 도와주며, 최첨단 실시간 모니터링 및 신속한 진단 능력으로 원활한 디지털 운영을 보장합니다. Image 3: API 오류 예시 API 오류는 여러 출처에서 발생할 수 있습니다. API 오류는 디지털 환경의 불가피한 부분이지만, 면밀한 모니터링, 신속한 대응 및 지속적인 개선 관행을 통해 그 영향을 크게 줄일 수 있습니다. API 오류의 일반적인 원인을 이해하고 해결을 위한 체계적인 접근을 채택함으로써, 개발자와 기업은 디지털 서비스의 회복력과 신뢰성을 향상시킬 수 있습니다.\", \"url\": \"https://apidog.com/kr/blog/what-is-api-failure-2/\", \"score\": 0.32633632, \"rank\": 3, \"query\": \"회사 API 접속 문제 해결 방법\"}]\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "📝 STEP 5: AIMessage\n",
            "────────────────────────────────────────────────────────────\n",
            "🤖 ASSISTANT RESPONSE:\n",
            "   API 접속 문제를 해결하기 위해 다음 단계를 확인해 주세요:\n",
            "\n",
            "### 1. **기본 확인 사항**\n",
            "   - **API 엔드포인트 URL**: `https://api.ourcompany.com/v1`을 사용 중인지 확인하세요.\n",
            "   - **인증 헤더**: 요청 헤더에 `Authorization: Bearer [유효한_API_키]`가 포함되어 있는지 확인하세요.\n",
            "   - **서비스 상태**: [상태 페이지](https://status.ourcompany.com)에서 현재 API 서비스 상태를 확인해 주세요.\n",
            "\n",
            "### 2. **일반적인 문제 해결 방법**\n",
            "   - **인증 오류**: API 키가 유효한지, 만료되지 않았는지 확인하세요.  \n",
            "     (예: `401 Unauthorized` 오류 발생 시)\n",
            "   - **속도 제한**: 요금제별 요청 한도를 초과했는지 확인하세요.  \n",
            "     (예: `429 Too Many Requests` 오류 발생 시)\n",
            "   - **네트워크 문제**: 방화벽 또는 프록시 설정으로 인해 차단되지 않았는지 확인하세요.\n",
            "   - **CORS 문제**: 브라우저에서 호출 시 `CORS` 오류가 발생할 수 있습니다. 백엔드 또는 프론트엔드 설정을 검토하세요.\n",
            "\n",
            "### 3. **추가 조치**\n",
            "   - **요청 예시**:  \n",
            "     ```http\n",
            "     GET https://api.ourcompany.com/v1/endpoint\n",
            "     Authorization: Bearer your_api_key_here\n",
            "     Content-Type: application/json\n",
            "     ```\n",
            "   - **도구 활용**: Postman 또는 `curl`로 테스트하여 클라이언트 측 문제인지 확인하세요.  \n",
            "     (예: `curl -H \"Authorization: Bearer your_api_key\" https://api.ourcompany.com/v1/endpoint`)\n",
            "\n",
            "### 4. **오류 메시지별 대응**\n",
            "   - **404 Not Found**: 엔드포인트 URL이 정확한지, 경로가 변경되지 않았는지 확인하세요.\n",
            "   - **500 Internal Server Error**: 일시적인 서버 오류일 수 있습니다. 잠시 후 재시도하거나 상태 페이지를 확인하세요.\n",
            "   - **연결 시간 초과**: 네트워크 지연 또는 DNS 문제일 수 있습니다. `ping` 또는 `traceroute`로 네트워크 상태를 진단하세요.\n",
            "\n",
            "### 5. **문의 사항**\n",
            "   - 위 단계로 해결되지 않을 경우, 다음 정보를 제공해 주시면 더 정확히 도와드릴 수 있습니다:\n",
            "     - 발생한 **정확한 오류 메시지** (예: HTTP 상태 코드, 에러 본문)\n",
            "     - 사용 중인 **API 엔드포인트** 및 **요청 예시** (헤더/바디 포함)\n",
            "     - 문제 발생 **시간대** 및 **빈도** (지속적/간헐적인지)\n",
            "\n",
            "내부 지식 베이스와 웹 검색 결과를 종합해 일반적인 API 문제 해결 방법을 안내드렸습니다. 추가 정보가 있다면 더 구체적인 지원이 가능합니다!\n",
            "\n",
            "�� TOKEN USAGE:\n",
            "   Input: 1811\n",
            "   Output: 522\n",
            "   Total: 2333\n",
            "\n",
            "================================================================================\n",
            "✅ CONVERSATION ANALYSIS COMPLETE\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🔍 TOOL USAGE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "📊 SUMMARY:\n",
            "   Total Tool Calls: 2\n",
            "   Total Tool Results: 2\n",
            "\n",
            "🔧 TOOL CALLS BREAKDOWN:\n",
            "   1. search_knowledge_base\n",
            "      Arguments: {'query': '회사 API 접속 문제 해결 방법'}\n",
            "      Reasoning: [API 접속 문제를 해결하기 위해 내부 지식 베이스에서 관련 해결 방법을 검색하고, 추가로 웹에서 최신 정보를 확인하기 위해 두 함수를 호출했습니다. 내부 지식 베이스에는 회사 ...\n",
            "   2. web_search\n",
            "      Arguments: {'query': '회사 API 접속 문제 해결 방법'}\n",
            "      Reasoning: [API 접속 문제를 해결하기 위해 내부 지식 베이스에서 관련 해결 방법을 검색하고, 추가로 웹에서 최신 정보를 확인하기 위해 두 함수를 호출했습니다. 내부 지식 베이스에는 회사 ...\n",
            "\n",
            "�� TOOL RESULTS BREAKDOWN:\n",
            "   1. search_knowledge_base\n",
            "      Result Length: 923 characters\n",
            "      Preview: [{\"content\": \"To integrate our API, use the base URL https://api.ourcompany.com/v1. Authentication r...\n",
            "   2. web_search\n",
            "      Result Length: 1692 characters\n",
            "      Preview: [{\"title\": \"REST API의 일반적인 문제 해결 - AppMaster\", \"content\": \"REST API의 일반적인 문제 해결 · 1. 일반적인 REST API 문...\n"
          ]
        }
      ],
      "source": [
        "pretty_print_conversation(response['messages'])\n",
        "\n",
        "# Analyze tool usage\n",
        "analyze_tool_usage(response['messages'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "대화의 내용을 살펴보면,\n",
        "\n",
        "> '`search_knowledge_base`는 회사 내부 기술 문서에서 공식 해결 방법을 찾기 위해, `web_search`는 일반적인 API 접속 문제 해결 방법을 보완하기 위해 호출~'\n",
        "\n",
        "이라고 LLM이 Reasoning하는 부분을 확인할 수 있습니다.\n",
        "\n",
        "LLM의 tool calling은 경우에 따라 다양한 방식으로 활용되기도 하고, 특정 방향으로 컨트롤 하는 것이 간단하지는 않습니다. 저희가 Prompt Enigneering을 통해 LLM의 작동방식을 통제하듯이, Tool Calling의 경우에도\n",
        "\n",
        "Tool의 이름, Tool의 상세설명을 더 자세하고 상세하게 다는 것으로 확인 할 수 있습니다. \n",
        "\n",
        "- Tool의 이름을 잘 짓는 것이 중요한 이유: [링크](https://slashpage.com/sujin-prompt-engineer/prompt_tips?post=d367nxm3qz86jmj98pv1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.3 ReAct Agent 직접 만들어보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "따라서 다음과 같은 과정을 거치면 ReAct Agent를 직접 만들어볼 수도 있습니다.\n",
        "\n",
        "1. `AgentState`를 선언해줍니다. 이 State는 Agent의 정보들을 기록하는 곳입니다. 간단하게 대화의 내용만 기록하도록 하겠습니다.\n",
        "\n",
        "2. `llm_node`를 생성합니다.\n",
        "    - 이 때 모델은 선언하고, 기존의 정의된 tool들을 사용할 수 있게, `model.bind_tools(tools)`을 해줍니다.\n",
        "\n",
        "3.  `tool_node`를 생성합니다.\n",
        "    - 모델이 tool calling을 할 때, 메세지에 담겨있는 \"name\"과 \"args\"를 확인해 tool을 실제로 실행하는 함수입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이번에는 노드를 실제로 구현해보겠습니다.\n",
        "\n",
        "- LangGraph에서 노드는 실제로 작업이 일어나는 곳으로, 간단하게 Python 함수로 구현돼있습니다.\n",
        "\n",
        "    - 이 때, 함수는 Graph의 State를 입력으로 받고, 내부적으로 State를 업데이트 한 다음 반환하는 형태입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3.1 AgentState 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    \"\"\"The state of the agent.\"\"\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3.2 LLM 노드 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
        "tools = [search_knowledge_base, web_search]\n",
        "model = model.bind_tools(tools)\n",
        "\n",
        "def llm_node(state: AgentState) -> Dict[str, Any]:\n",
        "    system = SystemMessage(\n",
        "        \"You are Agent, a concise and helpful support assistant. \"\n",
        "        \"Answer using only provided info and be kind.\"\n",
        "    )\n",
        "    resp = model.invoke([system] + state[\"messages\"])\n",
        "    return {\"messages\": [resp]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3.3 Tool 노드 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "def tool_node(state: AgentState):\n",
        "    outputs = []\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
        "        outputs.append(\n",
        "            ToolMessage(\n",
        "                content=json.dumps(tool_result),\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "    return {\"messages\": outputs}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"content\": \"To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\", \"score\": 0.5518820285797119, \"topic\": \"Password Reset\", \"category\": \"Account\", \"index\": 0, \"rank\": 1}, {\"content\": \"Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.\", \"score\": 0.3110274374485016, \"topic\": \"Security\", \"category\": \"Account\", \"index\": 5, \"rank\": 2}, {\"content\": \"Data export is available for all plans. Go to Account Settings > Data Export to request your data. The export will be emailed to you within 24 hours and includes all your account data in JSON format.\", \"score\": 0.2634652853012085, \"topic\": \"Data Export\", \"category\": \"Account\", \"index\": 4, \"rank\": 3}]\n"
          ]
        }
      ],
      "source": [
        "message = AIMessage(\n",
        "    content=\"\",\n",
        "    tool_calls=[{\n",
        "        \"name\": \"search_knowledge_base\",\n",
        "        \"args\": {\"query\": 'How can I reset my password?', \"top_k\": 3},\n",
        "        \"id\": \"tool_call_id\",\n",
        "        \"type\": \"tool_call\"\n",
        "    }]\n",
        ")\n",
        "response = tool_node(state={\"messages\": [message]})\n",
        "print(response['messages'][0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 ReAct 구조에 핵심이라고 할 수 있는 LLM에서 tools와 \\_\\_end\\_\\_를 조건부(conditional)연결하는 로직을 작성해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3.4 Conditional Edge 정의하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Conditional Edge`는 현재 그래프의 상태 (`state`)를 입력으로 받아 다음에 어느 것으로 향할 지 알려주는 Python 함수입니다.\n",
        "\n",
        "`tool_calling`을 할 지, 답변을 생성할 지에 대해서는 다음과 같은 로직으로 확인이 가능합니다:\n",
        "\n",
        "1. state에 담고있는 `messages`를 가장 최근 메세지를 확인했을 때, tool_calls 가 있으면 tool calling\n",
        "2. 그렇지 않으면 \"end\"로!\n",
        "\n",
        "위의 로직을 다음과 같이 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tool_call_or_end(state: AgentState):\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    if not last_message.tool_calls:\n",
        "        return \"end\"\n",
        "    else:\n",
        "        return \"tool_call_needed\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 이 Conditional Edge와 함께 그래프를 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3.5 ReAct 그래프 빌드하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m graph = builder.compile()\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m display(Image(\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agent-workshop/customer-support-agent/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph.py:702\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    693\u001b[39m     draw_mermaid_png,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    696\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    697\u001b[39m     curve_style=curve_style,\n\u001b[32m    698\u001b[39m     node_colors=node_colors,\n\u001b[32m    699\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    700\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    701\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agent-workshop/customer-support-agent/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:310\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    304\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    305\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    306\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    307\u001b[39m         )\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    318\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agent-workshop/customer-support-agent/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:463\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    459\u001b[39m     msg = (\n\u001b[32m    460\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    462\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    467\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
          ]
        }
      ],
      "source": [
        "builder = StateGraph(AgentState)\n",
        "builder.add_node(\"llm\", llm_node) # Node를 더할 때는 \"노드의 이름\", 함수 형태로 선언합니다.\n",
        "builder.add_node(\"tools\", tool_node)\n",
        "builder.set_entry_point(\"llm\")\n",
        "\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    # 시작점을 \"llm\" 으로 선정해줍니다.\n",
        "    \"llm\",\n",
        "    # 분기 조건에 해당하는 함수를 넣어줍니다.\n",
        "    tool_call_or_end,\n",
        "    # 마지막으로 return 되는 값에 따라 어디로 향할 지를 정해줍니다.\n",
        "    # \"end\"인 경우 그래프를 종료하는 곳으로\n",
        "    # \"tool_call_needed\"인 경우 \"tools\"로 향하게 됩니다.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"tool_call_needed\": \"tools\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# tools 노드에서 나온 결과는 다시 llm 노드로 향하게 됩니다.\n",
        "builder.add_edge(\"tools\", \"llm\")\n",
        "\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How can I reset my password?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "To reset your password, you can typically follow these general steps (no function calls needed as this is standard procedure):\n",
            "\n",
            "1. Go to the login page of the service you're using\n",
            "2. Click \"Forgot Password\" or similar link\n",
            "3. Enter your registered email address\n",
            "4. Check your email for a password reset link\n",
            "5. Click the link and follow instructions to create a new password\n",
            "\n",
            "If you need specific instructions for a particular service, please let me know which one you're referring to, and I can provide more detailed guidance. \n",
            "\n",
            "No function calls are needed since this is general knowledge about password reset processes.\n"
          ]
        }
      ],
      "source": [
        "for chunk in graph.stream(\n",
        "    {\"messages\": [(\"human\", \"How can I reset my password?\")]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    # 마지막 메시지 출력\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.4 Build Comprehensive Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 지금까지는 간단하게 ReAct Agent로 고객 응대 하는 에이전트를 만들어봤습니다.\n",
        "- 이 에이전트를 더 개선된 형태로 만드려면 어떤 방법이 있을까요?\n",
        "    - 우선 현재는 State에 대화내용만 기록하고 있습니다. 이런 구조보다는 State에 고객의 id, 고객의 정보, 고객의 질문을 따로 관리하는 것이 더 좋을 수 있습니다.\n",
        "    \n",
        "    - 또한 Tool을 사용했을 때의 결과도 따로 저장을 해두면, 특정 분기를 하는 과정에서 요긴하게 쓸 수도 있습니다. 예를 들어, 문서 검색을 해서 정보는 가져왔지만 유사도가 많이 낮다면 다른 분기를 할 수도 있습니다.\n",
        "\n",
        "    - 에이전트의 형태 자체도 새로 생각할 수 있습니다.\n",
        "        - 유저의 정보와 질문을 `llm` 노드로 향하기 전에 미리 입력을 받을 수 있습니다.\n",
        "        - `llm`이 `tools`에서 답변을 받은 뒤 답변을 생성하기 전에 **한번의 분기**를 추가하여\n",
        "            - 이 `tools`에서 받은 결과가 얼마나 **효과적인지** 판단한 후에\n",
        "                1. 효과적이지 않다면, 담당자에게 전달하거나\n",
        "                2. 효과적이라면, 답변을 생성하고 마칠 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이런 식으로 에이전트를 구성하는 것은 실제 업무의 흐름에 해당하는 Workflow를 상세하게 구현하고 해당 로직을 정교하게 설계하는 일이라고 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 우선 위에서 tool을 만들었던 방식과 동일하게 `fetch_customer_data` tool을 만들어보겠습니다.\n",
        "    - 이번 실습에서는 위에서 구현한 `load_customer_data`를 통해 데모 데이터 (`csv`)를 딕셔너리 형태로 변환해서 데이터 형태로 가지고 있습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.1 GraphState 정의하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "우선 위에서 생각해 본 워크플로우를 토대로 Agent가 들고 갈 정보를 다음과 같이 추릴 수 있습니다.\n",
        "- customer_question: str\n",
        "    - 사용자의 질문을 str 형태로 저장합니다.\n",
        "- customer_id: str\n",
        "    - 사용자의 id를 str 형태로 저장합니다.\n",
        "- customer_context: str\n",
        "    - 사용자의 정보를 str 형태로 저장합니다.\n",
        "- knowledge_base_results: List[Dict[str, Any]]\n",
        "    - knowledge_base_search의 결과를 딕셔너리가 담긴 리스트 형태로 저장합니다.\n",
        "- web_search_raw_results: List[Dict[str, Any]]\n",
        "    - web_search의 결과를 딕셔너리가 담긴 리스트 형태로 저장합니다.\n",
        "- specialist_info: Dict[str, Any]\n",
        "    - 담당자(specialist)의 정보를 딕셔너리로 저장합니다.\n",
        "- messages: Annotated[List[BaseMessage], add_messages]\n",
        "    - messages를 기록하고 langgraph의 `add_messages` Reducer를 사용해 자동으로 리스트에 추가되도록 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위의 정보들을 기록하는 GraphState를 우선 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphState(TypedDict):\n",
        "    customer_question: str\n",
        "    customer_id: str\n",
        "    customer_context: str\n",
        "    knowledge_base_results: List[Dict[str, Any]]\n",
        "    web_search_raw_results: List[Dict[str, Any]] \n",
        "    specialist_info: Dict[str, Any]\n",
        "    messages: Annotated[List[BaseMessage], add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.2 get_customer_id, get_customer_question 정의하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- GraphState에서 고객의 id, 고객의 정보, 고객의 질문을 따로 관리하기로 했습니다. \n",
        "\n",
        "- 이 부분은 사용자에게 직접 id를 입력받아 정보를 가져오고, 그 다음 질문을 입력받아 질문을 관리하는 로직으로 생각해보겠습니다.\n",
        "\n",
        "    - 실제로 서비스를 할 때는 사용자가 이미 로그인을 한 상태라면 그 때의 정보를 가지고 오도록 활용할 수도 있습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'CUST001': {'customer_id': 'CUST001', 'name': '김민준', 'email': 'kim.minjun@email.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-15', 'account_age_days': 365, 'previous_issues': 2}, 'CUST002': {'customer_id': 'CUST002', 'name': '이서연', 'email': 'lee.seoyeon@company.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-14', 'account_age_days': 180, 'previous_issues': 0}, 'CUST003': {'customer_id': 'CUST003', 'name': '박지훈', 'email': 'park.jihoon@tech.com', 'plan': 'Enterprise', 'subscription_status': 'active', 'last_login': '2024-01-13', 'account_age_days': 730, 'previous_issues': 5}, 'CUST004': {'customer_id': 'CUST004', 'name': '최수빈', 'email': 'choi.subin@startup.io', 'plan': 'Premium', 'subscription_status': 'expired', 'last_login': '2024-01-10', 'account_age_days': 90, 'previous_issues': 1}, 'CUST005': {'customer_id': 'CUST005', 'name': '정하은', 'email': 'jung.haeun@corp.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-16', 'account_age_days': 30, 'previous_issues': 0}, 'CUST006': {'customer_id': 'CUST006', 'name': '강현우', 'email': 'kang.hyunwoo@email.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-12', 'account_age_days': 450, 'previous_issues': 3}, 'CUST007': {'customer_id': 'CUST007', 'name': '윤지아', 'email': 'yoon.jia@business.com', 'plan': 'Enterprise', 'subscription_status': 'active', 'last_login': '2024-01-11', 'account_age_days': 1200, 'previous_issues': 8}, 'CUST008': {'customer_id': 'CUST008', 'name': '임도현', 'email': 'lim.dohyun@email.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-09', 'account_age_days': 60, 'previous_issues': 1}, 'CUST009': {'customer_id': 'CUST009', 'name': '오서준', 'email': 'oh.seojun@tech.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-08', 'account_age_days': 200, 'previous_issues': 2}, 'CUST010': {'customer_id': 'CUST010', 'name': '한예은', 'email': 'han.yeeun@company.com', 'plan': 'Basic', 'subscription_status': 'active', 'last_login': '2024-01-07', 'account_age_days': 15, 'previous_issues': 0}, 'CUST011': {'customer_id': 'CUST011', 'name': '최선웅', 'email': 'sunwoong.choi@company.com', 'plan': 'Premium', 'subscription_status': 'active', 'last_login': '2024-01-07', 'account_age_days': 15, 'previous_issues': 0}}\n"
          ]
        }
      ],
      "source": [
        "# Section1에서 정의한 customers\n",
        "print(customers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_customer_data(customer_id: str) -> str:\n",
        "    \"\"\"Fetch customer data from CRM system.\"\"\"\n",
        "    try:\n",
        "        customer_data = customers.get(customer_id, {})\n",
        "        \n",
        "        if not customer_data:\n",
        "            return \"No customer data found for this ID.\"\n",
        "        \n",
        "        context_parts = []\n",
        "        if customer_data.get('name'):\n",
        "            context_parts.append(f\"Name: {customer_data['name']}\")\n",
        "        if customer_data.get('email'):\n",
        "            context_parts.append(f\"Email: {customer_data['email']}\")\n",
        "        if customer_data.get('plan'):\n",
        "            context_parts.append(f\"Plan: {customer_data['plan']}\")\n",
        "        if customer_data.get('subscription_status'):\n",
        "            context_parts.append(f\"Status: {customer_data['subscription_status']}\")\n",
        "        if customer_data.get('account_age_days'):\n",
        "            context_parts.append(f\"Account Age: {customer_data['account_age_days']} days\")\n",
        "        if customer_data.get('previous_issues'):\n",
        "            context_parts.append(f\"Previous Issues: {customer_data['previous_issues']}\")\n",
        "        \n",
        "        customer_context = \"Customer Information:\\n\" + \"\\n\".join(context_parts)\n",
        "        # print(f\"✅ Customer context retrieved for {customer_id}\")\n",
        "        return customer_context\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"❌ Customer data fetch error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previous Issues: 2\n"
          ]
        }
      ],
      "source": [
        "print(fetch_customer_data(\"CUST001\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 함수를 바탕으로 두 노드, `get_customer_id`와 `get_customer_question`를 만들어보겠습니다.\n",
        "\n",
        "이 때는 langgraph의 `interrupt`를 활용해보겠습니다. `interrupt`는 말 그대로 사용자가 개입해 특정 액션을 하도록 입력을 주는 것으로 Python에서의 `input()`과 비슷한 역할이라고 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_customer_id(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Get customer ID from user.\"\"\"\n",
        "    customer_id = interrupt(\"🆔 Welcome to Customer Support! Can you please enter your Customer ID (CUSTXXX format)?\") # 사용자에게 Customer ID를 입력받습니다.\n",
        "    \n",
        "    # Validate customer ID format\n",
        "    if not customer_id or not customer_id.startswith(\"CUST\"):\n",
        "        customer_id = interrupt(f\"❌ Invalid format '{customer_id}'. Please enter your Customer ID in CUSTXXX format:\")\n",
        "    \n",
        "    customer_context = fetch_customer_data(customer_id)\n",
        "    print(f\"✅ Customer context retrieved for {customer_id}\")\n",
        "    print(f\"✅ Customer context: {customer_context}\")\n",
        "    return {\"customer_id\": customer_id, \"customer_context\": customer_context}\n",
        "\n",
        "def get_customer_question(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Get customer question from user.\"\"\"\n",
        "    customer_question = interrupt(\"❓ Do you need any help? Please describe your issue or question:\") # 사용자에게 질문을 입력받습니다.\n",
        "    \n",
        "    if not customer_question or len(customer_question.strip()) < 5:\n",
        "        customer_question = interrupt(\"❓ Please provide more details about your issue:\")\n",
        "    \n",
        "    return {\"customer_question\": customer_question}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "** 위에서 간단하게 구현한 get_customer_id에 멀티턴이 가능하도록 다양한 로직을 추가해보겠습니다.**\n",
        "\n",
        "- 실제 서비스와는 다를 수 있지만 다음의 경우들을 처리해보겠습니다.\n",
        "\n",
        "\n",
        "* 1. 고객 ID 형식 검증 (`if not customer_id ...`)\n",
        "    * 에러 메시지와 함께 재입력을 요청.\n",
        "\n",
        "* 2. 대화 상태 관리 (`if/elif/else`)\n",
        "    1. `if ...` (이전 고객과 ID가 다른 경우)\n",
        "        * 다른 고객이므로, 이전 대화 기록(검색 결과, 질문 등)을 **전부 초기화**.\n",
        "    2. `elif ...` (이전 고객 ID가 없는 새로운 세션)\n",
        "        * 첫 대화이므로, 모든 상태 변수를 **깨끗하게 초기화**.\n",
        "    3. `else` (이전 고객과 ID가 같은 경우)\n",
        "        * 동일 고객의 새 질문으로 간주하고, 고객 정보는 유지하되 **이전 검색 결과만 초기화**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_customer_id(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Get customer ID from user.\"\"\"\n",
        "    customer_id = interrupt(\"🆔 Welcome to Customer Support! Can you please enter your Customer ID (CUSTXXX format)?\")\n",
        "    \n",
        "    # Validate customer ID format\n",
        "    if not customer_id or not customer_id.startswith(\"CUST\"):\n",
        "        customer_id = interrupt(f\"❌ Invalid format '{customer_id}'. Please enter your Customer ID in CUSTXXX format:\")\n",
        "    \n",
        "    # Check if customer has changed - if so, reset search results\n",
        "    previous_customer_id = state.get(\"customer_id\", \"\")\n",
        "    update_dict = {\"customer_id\": customer_id}\n",
        "    \n",
        "    if previous_customer_id and previous_customer_id != customer_id:\n",
        "        print(f\"🔄 Customer changed from {previous_customer_id} to {customer_id} - resetting search results\")\n",
        "        update_dict.update({\n",
        "            \"knowledge_base_results\": [],\n",
        "            \"web_search_raw_results\": [],\n",
        "            \"specialist_info\": {},\n",
        "            \"customer_question\": \"\"  # Reset previous question too\n",
        "        })\n",
        "    elif not previous_customer_id:\n",
        "        print(f\"🆕 New session for customer {customer_id}\")\n",
        "        # Initialize empty results for new session\n",
        "        update_dict.update({\n",
        "            \"knowledge_base_results\": [],\n",
        "            \"web_search_raw_results\": [],\n",
        "            \"specialist_info\": {},\n",
        "            \"customer_question\": \"\"\n",
        "        })\n",
        "    else:\n",
        "        print(f\"🔄 Same customer {customer_id} - keeping existing context but resetting search results for new question\")\n",
        "        # Even for same customer, reset search results for new question\n",
        "        update_dict.update({\n",
        "            \"knowledge_base_results\": [],\n",
        "            \"web_search_raw_results\": [],\n",
        "            \"specialist_info\": {},\n",
        "            \"customer_question\": \"\"\n",
        "        })\n",
        "    \n",
        "    # Fetch customer context\n",
        "    customer_context = fetch_customer_data(customer_id)\n",
        "    update_dict[\"customer_context\"] = customer_context\n",
        "    \n",
        "    print(f\"✅ Customer context retrieved for {customer_id}\")\n",
        "    print(f\"✅ Customer context: {customer_context}\")\n",
        "    \n",
        "    return update_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.3 tool_node 정의하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tool_node를 먼저 정의해보겠습니다. GraphState에서 정의한대로 `knowledge_base_results`와 `web_search_raw_results`를 각각 툴을 사용할 때마다 업데이트 해줄 예정이기 때문에\n",
        "\n",
        "tool_node를 구현할 때 해당 로직도 함께 넣어주겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [search_knowledge_base, web_search]\n",
        "\n",
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "def tool_node(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Execute tools and update state with structured results.\"\"\"\n",
        "    \n",
        "    outputs = []\n",
        "    update = {\"messages\": []}\n",
        "    \n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        tool_result = None\n",
        "        for tool in tools:\n",
        "            if tool.name == tool_call[\"name\"]:\n",
        "                tool_result = tool.invoke(tool_call[\"args\"])\n",
        "                break\n",
        "        \n",
        "        outputs.append(\n",
        "            ToolMessage(\n",
        "                content=json.dumps(tool_result) if tool_result else \"Tool not found\",\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        if tool_call[\"name\"] == \"search_knowledge_base\": # tool_call이 search_knowledge_base인 경우\n",
        "            kb_results = tool_result if isinstance(tool_result, list) else []\n",
        "            update[\"knowledge_base_results\"] = kb_results # knowledge_base_results를 업데이트 해줍니다.\n",
        "            print(f\"📚 KB search completed with {len(kb_results)} results\")\n",
        "        \n",
        "        if tool_call[\"name\"] == \"web_search\": # tool_call이 web_search인 경우\n",
        "            web_results = tool_result if isinstance(tool_result, list) else []\n",
        "            update[\"web_search_raw_results\"] = web_results # web_search_raw_results를 업데이트 해줍니다.\n",
        "            print(f\"🌐 Web search completed with {len(web_results)} results\")\n",
        "    \n",
        "    update[\"messages\"] = outputs # 위에서 정의한 outputs를 업데이트 해줍니다.\n",
        "    return update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.4 LLM 노드 정의하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위에서 간단하게 이전 message를 보면서 대답하는 형태와 달리, 이번엔 저장돼있는 컨텍스트를 활용해 llm_node를 구현해보겠습니다.\n",
        "\n",
        "1. 우선 `customer_id`와 `customer_question`을 State에서 가져옵니다.\n",
        "    - 이를 통해 customer에 대한 정보, `customer_context`를 얻을 수 있습니다.\n",
        "2. LLM의 작동방식을 두 가지로 나누겠습니다.\n",
        "    1. 우선 가장 처음 LLM이 작동할 때는 유저의 Id, 정보 그리고 활용할 수 있는 툴의 정보를 바탕으로 판단을 합니다.\n",
        "    2. 만약 `tool_node`에서 툴에 대한 결과를 받아 온 경우, 이 tool_node에서 업데이트 된 context를 바탕으로 답변을 합니다.\n",
        "\n",
        "복잡해보이지만 두 가지 경우로 나눈 뒤, 각각 필요한 값을 state에서 가져와 prompt에 넣어주는 간단한 방식으로 구현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = StateGraph(GraphState)\n",
        "model = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "\n",
        "\n",
        "def llm_node(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Main LLM node that processes customer requests and calls tools.\"\"\"\n",
        "    customer_id = state.get(\"customer_id\", \"Unknown\")\n",
        "    customer_question = state.get(\"customer_question\", \"\")\n",
        "            \n",
        "        # Get customer context\n",
        "    customer_context = state.get(\"customer_context\", \"No customer context available\")\n",
        "    \n",
        "    print(f\"🤖 Processing question for {customer_id}: {customer_question[:100]}...\")\n",
        "    \n",
        "    # Check if we have tool results by looking at state fields directly\n",
        "    kb_results = state.get(\"knowledge_base_results\", [])\n",
        "    web_results = state.get(\"web_search_raw_results\", [])\n",
        "    has_tool_results = len(kb_results) > 0 or len(web_results) > 0\n",
        "    \n",
        "    if has_tool_results:\n",
        "        print(\"We have tool results\")\n",
        "\n",
        "        \n",
        "        # Format knowledge base results\n",
        "        kb_context = \"\"\n",
        "        if kb_results:\n",
        "            kb_formatted = []\n",
        "            for result in kb_results:\n",
        "                if isinstance(result, dict) and 'content' in result:\n",
        "                    topic = result.get('topic', 'Unknown')\n",
        "                    category = result.get('category', 'Unknown')\n",
        "                    content = result.get('content', '')\n",
        "                    score = result.get('score', 0.0)\n",
        "                    kb_formatted.append(f\"- [{category} - {topic}] (Score: {score:.1%}): {content}\")\n",
        "            kb_context = \"\\n\".join(kb_formatted)\n",
        "        \n",
        "        # Format web search results\n",
        "        web_context = \"\"\n",
        "        if web_results:\n",
        "            web_formatted = []\n",
        "            for result in web_results:\n",
        "                if isinstance(result, dict) and 'content' in result:\n",
        "                    title = result.get('title', 'Untitled')\n",
        "                    content = result.get('content', '')\n",
        "                    url = result.get('url', '')\n",
        "                    score = result.get('score', 0.0)\n",
        "                    web_formatted.append(f\"- [{title}] (Score: {score:.1%}): {content}\\n  Source: {url}\")\n",
        "            web_context = \"\\n\".join(web_formatted)\n",
        "        \n",
        "        # Construct comprehensive system prompt with all context\n",
        "        system_prompt = f\"\"\"You are a Customer Service Assistant helping customer {customer_id}.\n",
        "\n",
        "CUSTOMER CONTEXT:\n",
        "{customer_context}\n",
        "\n",
        "AVAILABLE INFORMATION:\"\"\"\n",
        "        \n",
        "        if kb_context:\n",
        "            system_prompt += f\"\"\"\n",
        "\n",
        "KNOWLEDGE BASE RESULTS:\n",
        "{kb_context}\"\"\"\n",
        "        \n",
        "        if web_context:\n",
        "            system_prompt += f\"\"\"\n",
        "\n",
        "WEB SEARCH RESULTS:\n",
        "{web_context}\"\"\"\n",
        "        \n",
        "        system_prompt += f\"\"\"\n",
        "\n",
        "CUSTOMER QUESTION: {customer_question}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "Use the above information to provide a comprehensive, helpful answer to the customer's question. \n",
        "Reference the relevant information from the search results and consider the customer's context.\n",
        "Be specific and cite the sources when appropriate.\n",
        "Do NOT call any tools - provide your final answer based on the available information.\"\"\"\n",
        "\n",
        "        system = SystemMessage(system_prompt)\n",
        "        \n",
        "    else:\n",
        "        print(\"First pass: LLM decides whether to use tools or answer directly\")\n",
        "        # First pass: LLM decides whether to use tools or answer directly\n",
        "        system = SystemMessage(\n",
        "            f\"You are a Customer Service Assistant helping customer {customer_id}.\\n\"\n",
        "            f\"Customer context: {customer_context}\\n\"\n",
        "            f\"Available tools: search_knowledge_base, web_search.\\n\\n\"\n",
        "            f\"Customer question: '{customer_question}'\\n\\n\"\n",
        "            f\"Instructions:\\n\"\n",
        "            f\"1. If you can fully answer this question with your knowledge, provide a complete, helpful response.\\n\"\n",
        "            f\"2. If you need specific information, call the appropriate tools to gather information.\\n\"\n",
        "            f\"3. If you cannot help or the request is beyond your capabilities, clearly state: 'I cannot help with this and need to escalate this to a specialist.'\"\n",
        "        )\n",
        "    \n",
        "    print(f\"🔧 System message: {system.content[:200]}...\")\n",
        "    print(f\"📊 Tool results available: KB={len(kb_results)}, Web={len(web_results)}\")\n",
        "    \n",
        "    # For tool results case, we have all context in system prompt, so just pass customer question\n",
        "    # For first pass, we need the model to potentially call tools\n",
        "    response = model_with_tools.invoke([system, HumanMessage(content=customer_question)])\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [response]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.5 Conditional Edge 정의하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "분기 처리를 위해 `tools_condition` 을 정의해보겠습니다.\n",
        "이전에 두 곳으로 나뉘었던 것과 달리 이번에는 세 곳의 노드로 향하는 `tools_condition`을 구현하겠습니다.\n",
        "\n",
        "1. \"tools\": 도구 사용이 필요할 때\n",
        "\n",
        "2. \"end\": 답변을 낼 수 있을 때\n",
        "\n",
        "3. \"escalate_to_specialist\": 전문가의 도움이 필요할 때\n",
        "    - Tool을 사용했을 때의 스코어로 검증합니다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tools_condition(state: GraphState) -> Literal[\"tools\", \"end\", \"escalate_to_specialist\"]:\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    \n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        print(\"🔄 LLM wants to use tools\")\n",
        "        return \"tools\"\n",
        "    else:\n",
        "        # Check if we have tool results and their quality\n",
        "        kb_results = state.get(\"knowledge_base_results\", [])\n",
        "        web_results = state.get(\"web_search_raw_results\", [])\n",
        "        \n",
        "        # Calculate scores from tool results\n",
        "        kb_scores = [r.get('score', 0.0) for r in kb_results if isinstance(r, dict) and 'score' in r]\n",
        "        web_scores = [r.get('score', 0.0) for r in web_results if isinstance(r, dict) and 'score' in r]\n",
        "        \n",
        "        max_kb_score = max(kb_scores) if kb_scores else 0.0\n",
        "        max_web_score = max(web_scores) if web_scores else 0.0\n",
        "        \n",
        "        print(f\"📊 Tool result quality: KB={max_kb_score:.1%}, Web={max_web_score:.1%}\")\n",
        "        \n",
        "\n",
        "        \n",
        "        has_good_kb = max_kb_score >= 0.25  # 25% threshold for KB\n",
        "        has_good_web = max_web_score >= 0.5  # 50% threshold for Web\n",
        "        has_any_tools_used = len(kb_results) > 0 or len(web_results) > 0\n",
        "        has_sufficient_info = has_good_kb or has_good_web\n",
        "        \n",
        "        if has_any_tools_used and not has_sufficient_info:\n",
        "            print(\"🔄 Tool results have low similarity scores - escalating\")\n",
        "            return \"escalate_to_specialist\"\n",
        "        else:\n",
        "            print(\"🔄 LLM provided final answer - ending conversation\")\n",
        "            return \"end\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.6 `escalate_to_specialist` 노드 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`escalate_to_specialist`는 \n",
        "1. 사용자의 질문을 분류하고 적절한 담당자를 찾아서 전달합니다.\n",
        "    - 이 때 state를 업데이트 합니다.\n",
        "2. 사용자에게 담당자에게 전달됐다는 메세지를 작성합니다.\n",
        "    - 실제로는 담당자에게 알림을 보내는 별도의 tool을 구현할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InquiryCategorySchema(BaseModel):\n",
        "    category: Literal[\"Technical\", \"Billing\", \"Account\", \"General\", \"Urgent\"]\n",
        "\n",
        "def classify_inquiry(customer_question: str) -> str:\n",
        "    \"\"\"Use LLM with structured output to classify customer inquiry.\"\"\"\n",
        "    llm = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
        "    llm_structured = llm.with_structured_output(InquiryCategorySchema)\n",
        "    \n",
        "    classification_prompt = f\"\"\"\n",
        "    Classify the following customer inquiry into one of these categories:\n",
        "    - Technical: Issues related to API, software, technical problems, bugs, system errors\n",
        "    - Billing: Payment issues, subscription problems, billing questions, refunds\n",
        "    - Account: Account management, login issues, password reset, profile changes\n",
        "    - General: General questions, information requests, non-specific inquiries\n",
        "    - Urgent: Critical issues requiring immediate attention, system outages, security breaches\n",
        "    \n",
        "    Customer Question: \"{customer_question}\"\n",
        "    \n",
        "    Classify this inquiry into the most appropriate category.\n",
        "    \"\"\"\n",
        "    \n",
        "    result = llm_structured.invoke(classification_prompt)\n",
        "    return result.category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def escalate_to_specialist(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Classify inquiry, assign specialist, and notify customer.\"\"\"\n",
        "    print(\"🚨 Escalating to specialist\")\n",
        "    \n",
        "    customer_question = state.get(\"customer_question\", \"\")\n",
        "    \n",
        "    # Classify inquiry for specialist assignment\n",
        "    inquiry_category = classify_inquiry(customer_question)\n",
        "    specialist_info = specialists.get(inquiry_category, specialists[\"General\"])\n",
        "    \n",
        "    print(f\"🏷️ Classified as: {inquiry_category}\")\n",
        "    print(f\"📋 Escalating to: {specialist_info['specialist']}\")\n",
        "    \n",
        "    # Simulate sending to specialist\n",
        "    print(f\"   ✉️ Escalation sent to {specialist_info.get('email', 'unknown')}\")\n",
        "    \n",
        "    # Generate customer notification\n",
        "    escalation_message = HumanMessage(\n",
        "        content=f\"I apologize, but I wasn't able to find sufficient information to help you with your inquiry. \"\n",
        "                f\"I'm escalating your case to our specialist team.\\n\\n\"\n",
        "                f\"🏷️ **Assigned Specialist**: {specialist_info.get('specialist', 'Unknown')}\\n\"\n",
        "                f\"📧 **Email**: {specialist_info.get('email', 'Unknown')}\\n\"\n",
        "                f\"🎯 **Expertise**: {', '.join(specialist_info.get('expertise', ['General Support']))}\\n\"\n",
        "                f\"⏱️ **Expected Response Time**: {specialist_info.get('response_time', 'Unknown')}\\n\\n\"\n",
        "                f\"They will have access to more resources and will be able to provide you with a comprehensive solution. \"\n",
        "                f\"Thank you for your patience!\"\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        \"specialist_info\": specialist_info,\n",
        "        \"messages\": [escalation_message]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4.7 Agent 빌드하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"get_customer_id\", get_customer_id)\n",
        "builder.add_node(\"get_customer_question\", get_customer_question)\n",
        "builder.add_node(\"llm\", llm_node)\n",
        "builder.add_node(\"tools\", tool_node)\n",
        "builder.add_node(\"escalate_to_specialist\", escalate_to_specialist)\n",
        "\n",
        "# Simple linear flow with conditional edges\n",
        "builder.set_entry_point(\"get_customer_id\")\n",
        "builder.add_edge(\"get_customer_id\", \"get_customer_question\")\n",
        "builder.add_edge(\"get_customer_question\", \"llm\")\n",
        "\n",
        "# ReAct-style routing from LLM\n",
        "builder.add_conditional_edges(\"llm\", tools_condition, {\n",
        "    \"tools\": \"tools\",\n",
        "    \"end\": END,\n",
        "    \"escalate_to_specialist\": \"escalate_to_specialist\"\n",
        "})\n",
        "\n",
        "# After tools, LLM generates final answer (no loop)\n",
        "builder.add_edge(\"tools\", \"llm\")\n",
        "\n",
        "# Escalation path\n",
        "builder.add_edge(\"escalate_to_specialist\", END)\n",
        "\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "checkpointer = InMemorySaver()\n",
        "graph = builder.compile(checkpointer=checkpointer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'__interrupt__': (Interrupt(value='🆔 Welcome to Customer Support! Can you please enter your Customer ID (CUSTXXX format)?', id='83944f026107abbb19c9165d21e9f18d'),)}\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [(\"human\", \"\")]},\n",
        "    stream_mode=\"updates\",\n",
        "    config=config,\n",
        "):\n",
        "    print(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🆕 New session for customer CUST001\n",
            "✅ Customer context retrieved for CUST001\n",
            "✅ Customer context: Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previous Issues: 2\n",
            "{'get_customer_id': {'customer_id': 'CUST001', 'knowledge_base_results': [], 'web_search_raw_results': [], 'specialist_info': {}, 'customer_question': '', 'customer_context': 'Customer Information:\\nName: 김민준\\nEmail: kim.minjun@email.com\\nPlan: Premium\\nStatus: active\\nAccount Age: 365 days\\nPrevious Issues: 2'}}\n",
            "\n",
            "\n",
            "{'__interrupt__': (Interrupt(value='❓ Do you need any help? Please describe your issue or question:', id='d96659bf6b8f8f14585e231fb7be2145'),)}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langgraph.types import Command\n",
        "for event in graph.stream(\n",
        "    Command(resume=\"CUST001\"),\n",
        "    stream_mode=\"updates\",\n",
        "    config=config,\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'get_customer_question': {'customer_question': 'How do I reset my password? (Look at the knowledge base please)'}}\n",
            "\n",
            "\n",
            "🤖 Processing question for CUST001: How do I reset my password? (Look at the knowledge base please)...\n",
            "First pass: LLM decides whether to use tools or answer directly\n",
            "🔧 System message: You are a Customer Service Assistant helping customer CUST001.\n",
            "Customer context: Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previous...\n",
            "📊 Tool results available: KB=0, Web=0\n",
            "🔄 LLM wants to use tools\n",
            "{'llm': {'messages': [AIMessage(content='[This function is ESSENTIAL because the customer explicitly asked to look at the knowledge base for password reset instructions. The query directly addresses their request, and the results will provide the necessary steps.]  \\n\\nAfter retrieving the knowledge base results, I will summarize the password reset process for you. If the information is insufficient, I may follow up with a web search.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-d745c14224a5456b9f0809514b430e42', 'function': {'arguments': '{\"query\": \"How to reset password\", \"top_k\": 3}', 'name': 'search_knowledge_base'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 891, 'total_tokens': 991, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d180bdb6-1042-4631-abca-c61d03cdd936-0', tool_calls=[{'name': 'search_knowledge_base', 'args': {'query': 'How to reset password', 'top_k': 3}, 'id': 'chatcmpl-tool-d745c14224a5456b9f0809514b430e42', 'type': 'tool_call'}], usage_metadata={'input_tokens': 891, 'output_tokens': 100, 'total_tokens': 991, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\n",
            "\n",
            "📚 KB search completed with 3 results\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"content\": \"To reset your password, go to the login page and click \\'Forgot Password\\'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\", \"score\": 0.5251910090446472, \"topic\": \"Password Reset\", \"category\": \"Account\", \"index\": 0, \"rank\": 1}, {\"content\": \"Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.\", \"score\": 0.3039703965187073, \"topic\": \"Security\", \"category\": \"Account\", \"index\": 5, \"rank\": 2}, {\"content\": \"Data export is available for all plans. Go to Account Settings > Data Export to request your data. The export will be emailed to you within 24 hours and includes all your account data in JSON format.\", \"score\": 0.2473747879266739, \"topic\": \"Data Export\", \"category\": \"Account\", \"index\": 4, \"rank\": 3}]', id='f46d82b0-988e-4f24-bec0-c3dadaaf1802', tool_call_id='chatcmpl-tool-d745c14224a5456b9f0809514b430e42')], 'knowledge_base_results': [{'content': \"To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\", 'score': 0.5251910090446472, 'topic': 'Password Reset', 'category': 'Account', 'index': 0, 'rank': 1}, {'content': 'Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.', 'score': 0.3039703965187073, 'topic': 'Security', 'category': 'Account', 'index': 5, 'rank': 2}, {'content': 'Data export is available for all plans. Go to Account Settings > Data Export to request your data. The export will be emailed to you within 24 hours and includes all your account data in JSON format.', 'score': 0.2473747879266739, 'topic': 'Data Export', 'category': 'Account', 'index': 4, 'rank': 3}]}}\n",
            "\n",
            "\n",
            "🤖 Processing question for CUST001: How do I reset my password? (Look at the knowledge base please)...\n",
            "We have tool results\n",
            "🔧 System message: You are a Customer Service Assistant helping customer CUST001.\n",
            "\n",
            "CUSTOMER CONTEXT:\n",
            "Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previou...\n",
            "📊 Tool results available: KB=3, Web=0\n",
            "📊 Tool result quality: KB=52.5%, Web=0.0%\n",
            "🔄 LLM provided final answer - ending conversation\n",
            "{'llm': {'messages': [AIMessage(content=\"안녕하세요, 김민준 고객님.  \\n\\n비밀번호 재설정에 대한 안내는 다음과 같습니다.  \\n\\n1. **로그인 페이지**에서 **'Forgot Password'**(비밀번호 찾기)를 클릭해 주세요.  \\n2. 등록된 이메일 주소(**kim.minjun@email.com**)를 입력한 후, 이메일로 전송된 재설정 링크를 확인하세요.  \\n3. 링크는 **24시간 이내**에 사용해야 하며, 새 비밀번호를 설정할 수 있습니다.  \\n\\n이 절차는 지식 베이스 문서 **[Account - Password Reset]** (일치도 52.5%)에 상세히 안내되어 있습니다. 추가 도움이 필요하시면 언제든지 문의해 주세요!  \\n\\n감사합니다.  \\nPremium 고객 지원팀 드림.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 1063, 'total_tokens': 1201, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--63fb00ab-8bf8-4abf-9632-159a93798ced-0', usage_metadata={'input_tokens': 1063, 'output_tokens': 138, 'total_tokens': 1201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for event in graph.stream(\n",
        "    Command(resume=\"How do I reset my password? (Look at the knowledge base please)\"),\n",
        "    stream_mode=\"updates\",\n",
        "    config=config,\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'__interrupt__': (Interrupt(value='🆔 Welcome to Customer Support! Can you please enter your Customer ID (CUSTXXX format)?', id='12dcaf0afc04063d7ff452dd7df345b5'),)}\n"
          ]
        }
      ],
      "source": [
        "for event in graph.stream(\n",
        "    {\"messages\": [(\"human\", \"\")]},\n",
        "    stream_mode=\"updates\",\n",
        "    config=config,\n",
        "):\n",
        "    print(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Same customer CUST001 - keeping existing context but resetting search results for new question\n",
            "✅ Customer context retrieved for CUST001\n",
            "✅ Customer context: Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previous Issues: 2\n",
            "{'get_customer_id': {'customer_id': 'CUST001', 'knowledge_base_results': [], 'web_search_raw_results': [], 'specialist_info': {}, 'customer_question': '', 'customer_context': 'Customer Information:\\nName: 김민준\\nEmail: kim.minjun@email.com\\nPlan: Premium\\nStatus: active\\nAccount Age: 365 days\\nPrevious Issues: 2'}}\n",
            "\n",
            "\n",
            "{'__interrupt__': (Interrupt(value='❓ Do you need any help? Please describe your issue or question:', id='0e434bf76a63ec3c68ba23b71856c3aa'),)}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langgraph.types import Command\n",
        "for event in graph.stream(\n",
        "    Command(resume=\"CUST001\"),\n",
        "    stream_mode=\"updates\",\n",
        "    config=config,\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'get_customer_question': {'customer_question': 'What is the ERROR CODE 02342? (Look at the knowledge base first please)'}}\n",
            "\n",
            "\n",
            "🤖 Processing question for CUST001: What is the ERROR CODE 02342? (Look at the knowledge base first please)...\n",
            "First pass: LLM decides whether to use tools or answer directly\n",
            "🔧 System message: You are a Customer Service Assistant helping customer CUST001.\n",
            "Customer context: Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previous...\n",
            "📊 Tool results available: KB=0, Web=0\n",
            "🔄 LLM wants to use tools\n",
            "{'llm': {'messages': [AIMessage(content='[This function is essential because the customer explicitly asked to check the knowledge base first for the error code explanation. The search will retrieve the most relevant information directly from our internal resources.]  \\n\\nIf the knowledge base doesn\\'t provide a match, I\\'ll follow up with a web search to ensure we cover all possible sources. Let me review the results first.  \\n\\n---  \\n**Update after knowledge base search**:  \\nIf the search returns no relevant results, I\\'ll proceed with:  \\n<tool_call>[web_search(query=\"ERROR CODE 02342\", max_results=3)]</tool_call>  \\n[This is necessary only if the knowledge base lacks information, as the error code may be external or newly documented online.]  \\n\\nLet me know if you\\'d like me to simulate results or proceed with either step!', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-be141b33fb0e4e14912d7b0567b348e6', 'function': {'arguments': '{\"query\": \"ERROR CODE 02342\", \"top_k\": 3}', 'name': 'search_knowledge_base'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 197, 'prompt_tokens': 903, 'total_tokens': 1100, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--18c089fb-d8a8-4efe-84a4-0b4a23df3467-0', tool_calls=[{'name': 'search_knowledge_base', 'args': {'query': 'ERROR CODE 02342', 'top_k': 3}, 'id': 'chatcmpl-tool-be141b33fb0e4e14912d7b0567b348e6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 903, 'output_tokens': 197, 'total_tokens': 1100, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\n",
            "\n",
            "📚 KB search completed with 3 results\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"content\": \"Our API rate limits are 1000 requests per hour for Basic plans, 5000 for Premium, and 10000 for Enterprise. If you exceed these limits, you\\'ll receive a 429 status code. Consider upgrading your plan for higher limits.\", \"score\": 0.22705721855163574, \"topic\": \"API Limits\", \"category\": \"Technical\", \"index\": 2, \"rank\": 1}, {\"content\": \"Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.\", \"score\": 0.2269381880760193, \"topic\": \"Security\", \"category\": \"Account\", \"index\": 5, \"rank\": 2}, {\"content\": \"To reset your password, go to the login page and click \\'Forgot Password\\'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\", \"score\": 0.19685779511928558, \"topic\": \"Password Reset\", \"category\": \"Account\", \"index\": 0, \"rank\": 3}]', id='698346bc-bb77-4a0d-9165-3dc219169c73', tool_call_id='chatcmpl-tool-be141b33fb0e4e14912d7b0567b348e6')], 'knowledge_base_results': [{'content': \"Our API rate limits are 1000 requests per hour for Basic plans, 5000 for Premium, and 10000 for Enterprise. If you exceed these limits, you'll receive a 429 status code. Consider upgrading your plan for higher limits.\", 'score': 0.22705721855163574, 'topic': 'API Limits', 'category': 'Technical', 'index': 2, 'rank': 1}, {'content': 'Two-factor authentication (2FA) can be enabled in Security Settings. We support SMS, email, and authenticator apps. 2FA is required for Enterprise accounts and recommended for all users.', 'score': 0.2269381880760193, 'topic': 'Security', 'category': 'Account', 'index': 5, 'rank': 2}, {'content': \"To reset your password, go to the login page and click 'Forgot Password'. Enter your email address and check your inbox for reset instructions. The reset link expires in 24 hours.\", 'score': 0.19685779511928558, 'topic': 'Password Reset', 'category': 'Account', 'index': 0, 'rank': 3}]}}\n",
            "\n",
            "\n",
            "🤖 Processing question for CUST001: What is the ERROR CODE 02342? (Look at the knowledge base first please)...\n",
            "We have tool results\n",
            "🔧 System message: You are a Customer Service Assistant helping customer CUST001.\n",
            "\n",
            "CUSTOMER CONTEXT:\n",
            "Customer Information:\n",
            "Name: 김민준\n",
            "Email: kim.minjun@email.com\n",
            "Plan: Premium\n",
            "Status: active\n",
            "Account Age: 365 days\n",
            "Previou...\n",
            "📊 Tool results available: KB=3, Web=0\n",
            "📊 Tool result quality: KB=22.7%, Web=0.0%\n",
            "🔄 Tool results have low similarity scores - escalating\n",
            "{'llm': {'messages': [AIMessage(content='Based on the provided knowledge base results and the customer\\'s question, there is no mention of **ERROR CODE 02342** in the available information. The knowledge base articles only cover topics related to API rate limits, security settings (2FA), and password resets, none of which reference this specific error code.  \\n\\nSince the error code is not documented in the knowledge base, I recommend the following steps:  \\n1. **Check the context** where the error occurred (e.g., API call, login attempt, or account management).  \\n2. **Review any accompanying error messages** for additional clues.  \\n3. If the issue persists, please provide more details about when and where the error occurred, and I can assist further or escalate the query to our technical support team.  \\n\\nFor now, no function calls are needed as the knowledge base does not contain relevant information.  \\n\\n**Final Answer**:  \\n\"안녕하세요, 김민준 고객님. 현재 제공된 지식 베이스에는 ERROR CODE 02342에 대한 정보가 없습니다. 해당 오류 코드가 발생한 상황(예: API 사용, 로그인 시도 등)과 추가 메시지를 알려주시면 더 정확히 도움을 드릴 수 있습니다. 필요시 기술 지원팀으로 문의도 가능합니다.\"  \\n\\n(Translation: \"Hello, Mr. Kim Min-jun. The error code 02342 is not documented in our current knowledge base. If you can share the context in which this error occurred (e.g., during an API call, login attempt, etc.) and any additional messages, I can assist you more precisely. If needed, we can also escalate this to our technical support team.\")', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 1093, 'total_tokens': 1429, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a2deebff-470e-4121-94a3-e078ab975801-0', usage_metadata={'input_tokens': 1093, 'output_tokens': 336, 'total_tokens': 1429, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\n",
            "\n",
            "🚨 Escalating to specialist\n",
            "🏷️ Classified as: Technical\n",
            "📋 Escalating to: Alex Chen\n",
            "   ✉️ Escalation sent to alex.chen@ourcompany.com\n",
            "{'escalate_to_specialist': {'specialist_info': {'specialist': 'Alex Chen', 'email': 'alex.chen@ourcompany.com', 'expertise': ['API Integration', 'System Architecture', 'Performance Issues'], 'response_time': '2-4 hours'}, 'messages': [HumanMessage(content=\"I apologize, but I wasn't able to find sufficient information to help you with your inquiry. I'm escalating your case to our specialist team.\\n\\n🏷️ **Assigned Specialist**: Alex Chen\\n📧 **Email**: alex.chen@ourcompany.com\\n🎯 **Expertise**: API Integration, System Architecture, Performance Issues\\n⏱️ **Expected Response Time**: 2-4 hours\\n\\nThey will have access to more resources and will be able to provide you with a comprehensive solution. Thank you for your patience!\", additional_kwargs={}, response_metadata={}, id='d70f9bb0-9688-4f03-80cf-f81afa2094e7')]}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for event in graph.stream(\n",
        "    Command(resume=\"What is the ERROR CODE 02342? (Look at the knowledge base first please)\"),\n",
        "    stream_mode=\"updates\",\n",
        "    config=config,\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "여기서는 넘어가서 `langgraph dev` 로 확인해봅시다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Customer Support Agent",
      "language": "python",
      "name": "customer-support-agent"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
